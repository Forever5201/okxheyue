#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIOrchestrator V2.1 æ€§èƒ½ä¼˜åŒ–æµ‹è¯•
æµ‹è¯•ä¼šè¯ç®¡ç†å’Œå·¥å…·è°ƒç”¨çš„æ€§èƒ½è¡¨ç°
"""

import time
import asyncio
import threading
import psutil
import json
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from typing import Dict, List, Any, Optional
from enum import Enum

# ç®€åŒ–çš„æšä¸¾å’Œæ•°æ®ç±»
class SessionType(Enum):
    MAIN_SESSION = "main_session"
    SUB_SESSION = "sub_session"

class ToolCategory(Enum):
    SIMPLE_TOOLS = "simple_tools"
    META_TOOLS = "meta_tools"
    THINKING_TOOLS = "thinking_tools"

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    operation_name: str
    start_time: float
    end_time: float
    duration: float
    memory_usage: float
    cpu_usage: float
    success: bool
    error_message: Optional[str] = None

@dataclass
class SessionMetrics:
    """ä¼šè¯æ€§èƒ½æŒ‡æ ‡"""
    session_id: str
    session_type: SessionType
    creation_time: float
    destruction_time: Optional[float]
    total_tools_called: int
    memory_peak: float
    cpu_peak: float

class PerformanceOptimizationTester:
    """æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.metrics: List[PerformanceMetrics] = []
        self.session_metrics: List[SessionMetrics] = []
        self.process = psutil.Process()
        
        # æ¨¡æ‹ŸAIOrchestratoré…ç½®
        self.config = {
            "max_sessions": 10,
            "session_timeout": 300,
            "tool_cache_size": 100,
            "thinking_cache_enabled": True,
            "async_processing": True
        }
        
        # æ¨¡æ‹Ÿä¼šè¯æ± 
        self.active_sessions = {}
        self.session_pool = []
        self.tool_cache = {}
        
        print("ğŸš€ æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def measure_performance(self, operation_name: str, func):
        """æ€§èƒ½æµ‹é‡æ–¹æ³•"""
        def wrapper(*args, **kwargs):
            start_time = time.time()
            start_memory = self.process.memory_info().rss / 1024 / 1024  # MB
            start_cpu = self.process.cpu_percent()
            
            success = True
            error_message = None
            result = None
            
            try:
                result = func(self, *args, **kwargs)
            except Exception as e:
                success = False
                error_message = str(e)
            
            end_time = time.time()
            end_memory = self.process.memory_info().rss / 1024 / 1024  # MB
            end_cpu = self.process.cpu_percent()
            
            metrics = PerformanceMetrics(
                operation_name=operation_name,
                start_time=start_time,
                end_time=end_time,
                duration=end_time - start_time,
                memory_usage=end_memory - start_memory,
                cpu_usage=max(start_cpu, end_cpu),
                success=success,
                error_message=error_message
            )
            
            self.metrics.append(metrics)
            return result
        return wrapper
    
    def create_session(self, session_type: SessionType, config: Dict[str, Any]) -> str:
        """åˆ›å»ºä¼šè¯ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        session_id = f"{session_type.value}_{int(time.time() * 1000)}"
        
        # ä¼šè¯æ± ä¼˜åŒ–ï¼šé‡ç”¨å·²é”€æ¯çš„ä¼šè¯å¯¹è±¡
        if self.session_pool:
            session_obj = self.session_pool.pop()
            session_obj.reset(session_id, session_type, config)
        else:
            session_obj = self._create_new_session(session_id, session_type, config)
        
        self.active_sessions[session_id] = session_obj
        
        # è®°å½•ä¼šè¯æŒ‡æ ‡
        session_metrics = SessionMetrics(
            session_id=session_id,
            session_type=session_type,
            creation_time=time.time(),
            destruction_time=None,
            total_tools_called=0,
            memory_peak=self.process.memory_info().rss / 1024 / 1024,
            cpu_peak=self.process.cpu_percent()
        )
        self.session_metrics.append(session_metrics)
        
        return session_id
    
    def _create_new_session(self, session_id: str, session_type: SessionType, config: Dict[str, Any]):
        """åˆ›å»ºæ–°ä¼šè¯å¯¹è±¡"""
        return {
            "id": session_id,
            "type": session_type,
            "config": config,
            "created_at": time.time(),
            "tools_called": 0,
            "cache": {}
        }
    
    def destroy_session(self, session_id: str):
        """é”€æ¯ä¼šè¯ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if session_id in self.active_sessions:
            session_obj = self.active_sessions.pop(session_id)
            
            # ä¼šè¯æ± ä¼˜åŒ–ï¼šå›æ”¶ä¼šè¯å¯¹è±¡ä¾›é‡ç”¨
            if len(self.session_pool) < self.config["max_sessions"]:
                session_obj["cache"].clear()  # æ¸…ç†ç¼“å­˜
                self.session_pool.append(session_obj)
            
            # æ›´æ–°ä¼šè¯æŒ‡æ ‡
            for metrics in self.session_metrics:
                if metrics.session_id == session_id:
                    metrics.destruction_time = time.time()
                    metrics.total_tools_called = session_obj["tools_called"]
                    break
    
    def call_tool_cached(self, tool_name: str, params: Dict[str, Any], session_id: str) -> Dict[str, Any]:
        """ç¼“å­˜ä¼˜åŒ–çš„å·¥å…·è°ƒç”¨"""
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"{tool_name}_{hash(json.dumps(params, sort_keys=True))}"
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.tool_cache:
            return {
                "result": self.tool_cache[cache_key],
                "cached": True,
                "execution_time": 0.001  # ç¼“å­˜å‘½ä¸­æ—¶é—´
            }
        
        # æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œ
        start_time = time.time()
        result = self._execute_tool(tool_name, params)
        execution_time = time.time() - start_time
        
        # æ›´æ–°ç¼“å­˜
        if len(self.tool_cache) < self.config["tool_cache_size"]:
            self.tool_cache[cache_key] = result
        
        # æ›´æ–°ä¼šè¯ç»Ÿè®¡
        if session_id in self.active_sessions:
            self.active_sessions[session_id]["tools_called"] += 1
        
        return {
            "result": result,
            "cached": False,
            "execution_time": execution_time
        }
    
    def _execute_tool(self, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œ"""
        # æ¨¡æ‹Ÿä¸åŒå·¥å…·çš„æ‰§è¡Œæ—¶é—´
        execution_times = {
            "sequentialthinking": 0.1,
            "data_processing": 0.05,
            "technical_analysis": 0.08,
            "risk_management": 0.03
        }
        
        time.sleep(execution_times.get(tool_name, 0.02))
        
        return {
            "tool": tool_name,
            "params": params,
            "result": f"æ‰§è¡Œç»“æœ_{tool_name}_{int(time.time() * 1000)}",
            "timestamp": time.time()
        }
    
    def execute_concurrent_tools(self, tool_calls: List[Dict[str, Any]], session_id: str) -> List[Dict[str, Any]]:
        """å¹¶å‘å·¥å…·è°ƒç”¨ä¼˜åŒ–"""
        results = []
        
        if self.config["async_processing"] and len(tool_calls) > 1:
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œ
            with ThreadPoolExecutor(max_workers=min(len(tool_calls), 4)) as executor:
                future_to_call = {
                    executor.submit(
                        self.call_tool_cached,
                        call["tool_name"],
                        call["params"],
                        session_id
                    ): call for call in tool_calls
                }
                
                for future in as_completed(future_to_call):
                    try:
                        result = future.result()
                        results.append(result)
                    except Exception as e:
                        results.append({"error": str(e), "cached": False})
        else:
            # ä¸²è¡Œæ‰§è¡Œ
            for call in tool_calls:
                result = self.call_tool_cached(
                    call["tool_name"],
                    call["params"],
                    session_id
                )
                results.append(result)
        
        return results
    
    def optimize_memory_usage(self):
        """å†…å­˜ä½¿ç”¨ä¼˜åŒ–"""
        # æ¸…ç†è¿‡æœŸç¼“å­˜
        current_time = time.time()
        expired_sessions = []
        
        for session_id, session_obj in self.active_sessions.items():
            if current_time - session_obj["created_at"] > self.config["session_timeout"]:
                expired_sessions.append(session_id)
        
        for session_id in expired_sessions:
            self.destroy_session(session_id)
        
        # æ¸…ç†å·¥å…·ç¼“å­˜ï¼ˆLRUç­–ç•¥ï¼‰
        if len(self.tool_cache) > self.config["tool_cache_size"] * 0.8:
            # ç®€å•çš„ç¼“å­˜æ¸…ç†ï¼šåˆ é™¤ä¸€åŠç¼“å­˜
            cache_items = list(self.tool_cache.items())
            self.tool_cache = dict(cache_items[len(cache_items)//2:])
        
        return {
            "expired_sessions_cleaned": len(expired_sessions),
            "cache_size_after_cleanup": len(self.tool_cache),
            "active_sessions": len(self.active_sessions)
        }
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        if not self.metrics:
            return {"message": "æš‚æ— æ€§èƒ½æ•°æ®"}
        
        # æŒ‰æ“ä½œç±»å‹åˆ†ç»„ç»Ÿè®¡
        operation_stats = {}
        for metric in self.metrics:
            op_name = metric.operation_name
            if op_name not in operation_stats:
                operation_stats[op_name] = {
                    "count": 0,
                    "total_duration": 0,
                    "total_memory": 0,
                    "max_duration": 0,
                    "min_duration": float('inf'),
                    "success_rate": 0,
                    "errors": []
                }
            
            stats = operation_stats[op_name]
            stats["count"] += 1
            stats["total_duration"] += metric.duration
            stats["total_memory"] += metric.memory_usage
            stats["max_duration"] = max(stats["max_duration"], metric.duration)
            stats["min_duration"] = min(stats["min_duration"], metric.duration)
            
            if metric.success:
                stats["success_rate"] += 1
            else:
                stats["errors"].append(metric.error_message)
        
        # è®¡ç®—å¹³å‡å€¼å’ŒæˆåŠŸç‡
        for op_name, stats in operation_stats.items():
            if stats["count"] > 0:
                stats["avg_duration"] = stats["total_duration"] / stats["count"]
                stats["avg_memory"] = stats["total_memory"] / stats["count"]
                stats["success_rate"] = stats["success_rate"] / stats["count"]
                if stats["min_duration"] == float('inf'):
                    stats["min_duration"] = 0
        
        # ä¼šè¯ç»Ÿè®¡
        session_stats = {
            "total_sessions_created": len(self.session_metrics),
            "active_sessions": len(self.active_sessions),
            "session_pool_size": len(self.session_pool),
            "cache_size": len(self.tool_cache)
        }
        
        return {
            "performance_summary": {
                "test_duration": time.time() - (self.metrics[0].start_time if self.metrics else time.time()),
                "total_operations": len(self.metrics),
                "operation_statistics": operation_stats,
                "session_statistics": session_stats,
                "current_memory_usage": self.process.memory_info().rss / 1024 / 1024,
                "current_cpu_usage": self.process.cpu_percent()
            }
        }

def test_session_management_performance():
    """æµ‹è¯•ä¼šè¯ç®¡ç†æ€§èƒ½"""
    print("\nğŸ§ª æµ‹è¯•1: ä¼šè¯ç®¡ç†æ€§èƒ½")
    
    tester = PerformanceOptimizationTester()
    
    # åŒ…è£…æ€§èƒ½æµ‹é‡çš„æ–¹æ³•
    create_session_measured = tester.measure_performance("session_creation", tester.create_session.__func__)
    destroy_session_measured = tester.measure_performance("session_destruction", tester.destroy_session.__func__)
    
    # æ‰¹é‡åˆ›å»ºä¼šè¯
    session_ids = []
    for i in range(20):
        session_id = create_session_measured(
            SessionType.SUB_SESSION if i % 2 else SessionType.MAIN_SESSION,
            {"task_name": f"æµ‹è¯•ä»»åŠ¡_{i}", "timeout": 60}
        )
        session_ids.append(session_id)
    
    # æ‰¹é‡é”€æ¯ä¼šè¯
    for session_id in session_ids[:10]:
        destroy_session_measured(session_id)
    
    # å†æ¬¡åˆ›å»ºä¼šè¯ï¼ˆæµ‹è¯•ä¼šè¯æ± é‡ç”¨ï¼‰
    for i in range(5):
        session_id = create_session_measured(
            SessionType.SUB_SESSION,
            {"task_name": f"é‡ç”¨æµ‹è¯•_{i}", "timeout": 60}
        )
        session_ids.append(session_id)
    
    print("âœ… ä¼šè¯ç®¡ç†æ€§èƒ½æµ‹è¯•å®Œæˆ")
    return tester

def test_tool_call_performance(tester):
    """æµ‹è¯•å·¥å…·è°ƒç”¨æ€§èƒ½"""
    print("\nğŸ§ª æµ‹è¯•2: å·¥å…·è°ƒç”¨æ€§èƒ½")
    
    session_id = tester.create_session(
        SessionType.MAIN_SESSION,
        {"task_name": "å·¥å…·è°ƒç”¨æµ‹è¯•", "cache_enabled": True}
    )
    
    # åŒ…è£…æ€§èƒ½æµ‹é‡çš„æ–¹æ³•
    call_tool_measured = tester.measure_performance("tool_call_cached", tester.call_tool_cached.__func__)
    
    # æµ‹è¯•ç¼“å­˜æ•ˆæœ
    tool_calls = [
        {"tool_name": "sequentialthinking", "params": {"problem": "æµ‹è¯•é—®é¢˜1"}},
        {"tool_name": "data_processing", "params": {"data": "æµ‹è¯•æ•°æ®"}},
        {"tool_name": "sequentialthinking", "params": {"problem": "æµ‹è¯•é—®é¢˜1"}},  # é‡å¤è°ƒç”¨
        {"tool_name": "technical_analysis", "params": {"indicator": "RSI"}}
    ]
    
    # ä¸²è¡Œè°ƒç”¨
    for call in tool_calls:
        result = call_tool_measured(call["tool_name"], call["params"], session_id)
        cache_status = "ç¼“å­˜å‘½ä¸­" if result["cached"] else "æ–°è®¡ç®—"
        print(f"   {call['tool_name']}: {cache_status} ({result['execution_time']:.3f}s)")
    
    print("âœ… å·¥å…·è°ƒç”¨æ€§èƒ½æµ‹è¯•å®Œæˆ")
    return tester

def test_concurrent_processing_performance(tester):
    """æµ‹è¯•å¹¶å‘å¤„ç†æ€§èƒ½"""
    print("\nğŸ§ª æµ‹è¯•3: å¹¶å‘å¤„ç†æ€§èƒ½")
    
    session_id = tester.create_session(
        SessionType.MAIN_SESSION,
        {"task_name": "å¹¶å‘æµ‹è¯•", "async_enabled": True}
    )
    
    # åŒ…è£…æ€§èƒ½æµ‹é‡çš„æ–¹æ³•
    execute_concurrent_measured = tester.measure_performance("concurrent_tool_calls", tester.execute_concurrent_tools.__func__)
    
    # å‡†å¤‡å¹¶å‘å·¥å…·è°ƒç”¨
    concurrent_calls = [
        {"tool_name": "sequentialthinking", "params": {"problem": f"å¹¶å‘é—®é¢˜_{i}"}}
        for i in range(8)
    ]
    
    # æµ‹è¯•å¹¶å‘æ‰§è¡Œ
    start_time = time.time()
    results = execute_concurrent_measured(concurrent_calls, session_id)
    concurrent_duration = time.time() - start_time
    
    # æµ‹è¯•ä¸²è¡Œæ‰§è¡Œï¼ˆå¯¹æ¯”ï¼‰
    tester.config["async_processing"] = False
    start_time = time.time()
    serial_results = execute_concurrent_measured(concurrent_calls, session_id)
    serial_duration = time.time() - start_time
    tester.config["async_processing"] = True
    
    speedup = serial_duration / concurrent_duration if concurrent_duration > 0 else 1
    print(f"   å¹¶å‘æ‰§è¡Œæ—¶é—´: {concurrent_duration:.3f}s")
    print(f"   ä¸²è¡Œæ‰§è¡Œæ—¶é—´: {serial_duration:.3f}s")
    print(f"   æ€§èƒ½æå‡: {speedup:.2f}x")
    
    print("âœ… å¹¶å‘å¤„ç†æ€§èƒ½æµ‹è¯•å®Œæˆ")
    return tester

def test_memory_optimization_performance(tester):
    """æµ‹è¯•å†…å­˜ä¼˜åŒ–æ€§èƒ½"""
    print("\nğŸ§ª æµ‹è¯•4: å†…å­˜ä¼˜åŒ–æ€§èƒ½")
    
    # åŒ…è£…æ€§èƒ½æµ‹é‡çš„æ–¹æ³•
    optimize_memory_measured = tester.measure_performance("memory_optimization", tester.optimize_memory_usage.__func__)
    
    # åˆ›å»ºå¤§é‡ä¼šè¯å’Œç¼“å­˜
    for i in range(50):
        session_id = tester.create_session(
            SessionType.SUB_SESSION,
            {"task_name": f"å†…å­˜æµ‹è¯•_{i}", "timeout": 1}  # çŸ­è¶…æ—¶
        )
        
        # åˆ›å»ºç¼“å­˜é¡¹
        for j in range(5):
            tester.call_tool_cached(
                "data_processing",
                {"data": f"æµ‹è¯•æ•°æ®_{i}_{j}"},
                session_id
            )
    
    memory_before = tester.process.memory_info().rss / 1024 / 1024
    cache_size_before = len(tester.tool_cache)
    sessions_before = len(tester.active_sessions)
    
    # ç­‰å¾…ä¼šè¯è¿‡æœŸ
    time.sleep(2)
    
    # æ‰§è¡Œå†…å­˜ä¼˜åŒ–
    optimization_result = optimize_memory_measured()
    
    memory_after = tester.process.memory_info().rss / 1024 / 1024
    cache_size_after = len(tester.tool_cache)
    sessions_after = len(tester.active_sessions)
    
    print(f"   ä¼˜åŒ–å‰: {sessions_before}ä¸ªä¼šè¯, {cache_size_before}ä¸ªç¼“å­˜é¡¹, {memory_before:.1f}MB")
    print(f"   ä¼˜åŒ–å: {sessions_after}ä¸ªä¼šè¯, {cache_size_after}ä¸ªç¼“å­˜é¡¹, {memory_after:.1f}MB")
    print(f"   æ¸…ç†ç»“æœ: {optimization_result}")
    
    print("âœ… å†…å­˜ä¼˜åŒ–æ€§èƒ½æµ‹è¯•å®Œæˆ")
    return tester

def test_stress_testing(tester):
    """å‹åŠ›æµ‹è¯•"""
    print("\nğŸ§ª æµ‹è¯•5: ç³»ç»Ÿå‹åŠ›æµ‹è¯•")
    
    # æ¨¡æ‹Ÿé«˜è´Ÿè½½åœºæ™¯
    stress_duration = 10  # 10ç§’å‹åŠ›æµ‹è¯•
    start_time = time.time()
    operation_count = 0
    
    while time.time() - start_time < stress_duration:
        # éšæœºæ“ä½œ
        import random
        operation = random.choice(["create_session", "call_tool", "destroy_session"])
        
        try:
            if operation == "create_session":
                session_id = tester.create_session(
                    random.choice([SessionType.MAIN_SESSION, SessionType.SUB_SESSION]),
                    {"task_name": f"å‹åŠ›æµ‹è¯•_{operation_count}", "timeout": 30}
                )
            
            elif operation == "call_tool" and tester.active_sessions:
                session_id = random.choice(list(tester.active_sessions.keys()))
                tool_name = random.choice(["sequentialthinking", "data_processing", "technical_analysis"])
                tester.call_tool_cached(
                    tool_name,
                    {"param": f"å‹åŠ›æµ‹è¯•_{operation_count}"},
                    session_id
                )
            
            elif operation == "destroy_session" and tester.active_sessions:
                session_id = random.choice(list(tester.active_sessions.keys()))
                tester.destroy_session(session_id)
            
            operation_count += 1
            
        except Exception as e:
            print(f"   å‹åŠ›æµ‹è¯•é”™è¯¯: {e}")
    
    # å®šæœŸå†…å­˜ä¼˜åŒ–
    tester.optimize_memory_usage()
    
    print(f"   å‹åŠ›æµ‹è¯•å®Œæˆ: {operation_count}æ¬¡æ“ä½œ in {stress_duration}s")
    print(f"   å¹³å‡æ“ä½œé€Ÿç‡: {operation_count/stress_duration:.1f} ops/s")
    
    print("âœ… ç³»ç»Ÿå‹åŠ›æµ‹è¯•å®Œæˆ")
    return tester

def test_performance_monitoring(tester):
    """æµ‹è¯•æ€§èƒ½ç›‘æ§"""
    print("\nğŸ§ª æµ‹è¯•6: æ€§èƒ½ç›‘æ§å’ŒæŠ¥å‘Š")
    
    # è·å–æ€§èƒ½æ‘˜è¦
    summary = tester.get_performance_summary()
    
    print("\nğŸ“Š æ€§èƒ½æµ‹è¯•æ‘˜è¦:")
    perf_summary = summary["performance_summary"]
    
    print(f"   æµ‹è¯•æ€»æ—¶é•¿: {perf_summary['test_duration']:.2f}s")
    print(f"   æ€»æ“ä½œæ•°: {perf_summary['total_operations']}")
    print(f"   å½“å‰å†…å­˜ä½¿ç”¨: {perf_summary['current_memory_usage']:.1f}MB")
    print(f"   å½“å‰CPUä½¿ç”¨: {perf_summary['current_cpu_usage']:.1f}%")
    
    print("\nğŸ“ˆ æ“ä½œæ€§èƒ½ç»Ÿè®¡:")
    for op_name, stats in perf_summary["operation_statistics"].items():
        print(f"   {op_name}:")
        print(f"     è°ƒç”¨æ¬¡æ•°: {stats['count']}")
        print(f"     å¹³å‡è€—æ—¶: {stats['avg_duration']:.4f}s")
        print(f"     æœ€å¤§è€—æ—¶: {stats['max_duration']:.4f}s")
        print(f"     æœ€å°è€—æ—¶: {stats['min_duration']:.4f}s")
        print(f"     æˆåŠŸç‡: {stats['success_rate']:.2%}")
        if stats['errors']:
            print(f"     é”™è¯¯: {len(stats['errors'])}ä¸ª")
    
    print("\nğŸ”§ ä¼šè¯ç»Ÿè®¡:")
    session_stats = perf_summary["session_statistics"]
    for key, value in session_stats.items():
        print(f"   {key}: {value}")
    
    print("âœ… æ€§èƒ½ç›‘æ§æµ‹è¯•å®Œæˆ")
    
    return summary

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ AIOrchestrator V2.1 æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å¼€å§‹")
    print("=" * 60)
    
    try:
        # æ‰§è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•
        tester = test_session_management_performance()
        tester = test_tool_call_performance(tester)
        tester = test_concurrent_processing_performance(tester)
        tester = test_memory_optimization_performance(tester)
        tester = test_stress_testing(tester)
        summary = test_performance_monitoring(tester)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å®Œæˆ!")
        
        # æ€§èƒ½ä¼˜åŒ–å»ºè®®
        print("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        perf_data = summary["performance_summary"]
        
        # åˆ†æä¼šè¯ç®¡ç†æ€§èƒ½
        session_ops = perf_data["operation_statistics"].get("session_creation", {})
        if session_ops.get("avg_duration", 0) > 0.01:
            print("   âš ï¸  ä¼šè¯åˆ›å»ºè€—æ—¶è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–ä¼šè¯æ± ç®¡ç†")
        else:
            print("   âœ… ä¼šè¯ç®¡ç†æ€§èƒ½è‰¯å¥½")
        
        # åˆ†æå·¥å…·è°ƒç”¨æ€§èƒ½
        tool_ops = perf_data["operation_statistics"].get("tool_call_cached", {})
        if tool_ops.get("avg_duration", 0) > 0.05:
            print("   âš ï¸  å·¥å…·è°ƒç”¨è€—æ—¶è¾ƒé•¿ï¼Œå»ºè®®å¢åŠ ç¼“å­˜å¤§å°")
        else:
            print("   âœ… å·¥å…·è°ƒç”¨æ€§èƒ½è‰¯å¥½")
        
        # åˆ†æå†…å­˜ä½¿ç”¨
        if perf_data["current_memory_usage"] > 500:  # 500MB
            print("   âš ï¸  å†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼Œå»ºè®®å¢åŠ æ¸…ç†é¢‘ç‡")
        else:
            print("   âœ… å†…å­˜ä½¿ç”¨åˆç†")
        
        # åˆ†æå¹¶å‘æ€§èƒ½
        concurrent_ops = perf_data["operation_statistics"].get("concurrent_tool_calls", {})
        if concurrent_ops.get("count", 0) > 0:
            print("   âœ… å¹¶å‘å¤„ç†åŠŸèƒ½æ­£å¸¸")
        
        print("\nğŸ”§ ä¼˜åŒ–é…ç½®å»ºè®®:")
        print("   - ä¼šè¯æ± å¤§å°: 10-20")
        print("   - å·¥å…·ç¼“å­˜å¤§å°: 100-200")
        print("   - å¹¶å‘çº¿ç¨‹æ•°: 4-8")
        print("   - ä¼šè¯è¶…æ—¶: 300-600ç§’")
        print("   - å†…å­˜æ¸…ç†é—´éš”: 60-120ç§’")
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()