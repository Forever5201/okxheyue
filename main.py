"""
AIäº¤æ˜“ç³»ç»Ÿä¸»å…¥å£
Main Entry Point for AI Trading System

é›†æˆæ•°æ®è·å–ã€æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ã€MCPæœåŠ¡å’ŒAIåˆ†æ
"""

import os
import json
import time
import asyncio
import schedule
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from dotenv import load_dotenv

from typing import Dict, Any
from src.logger import setup_logger
from src.enhanced_data_manager import EnhancedDataManager
from src.mcp_service import app as mcp_app
from src.message_queue import MessageQueueManager
from src.analysis_agent import AnalysisAgent

logger = setup_logger()

class AITradingSystem:
    def __init__(self):
        """åˆå§‹åŒ–AIäº¤æ˜“ç³»ç»Ÿ"""
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
        required_vars = ['OKX_API_KEY', 'OKX_API_SECRET', 'OKX_API_PASSPHRASE', 'MCP_API_KEY', 'DASHSCOPE_API_KEY']
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            error_msg = f"Missing required environment variables: {', '.join(missing_vars)}"
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        try:
            self.data_manager = EnhancedDataManager()
            logger.info("AI Trading System initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize data manager: {e}")
            raise
        
        # åˆå§‹åŒ–æ¶ˆæ¯é˜Ÿåˆ—å’Œä»£ç†ç³»ç»Ÿ
        self._init_agent_system()
        
        # ç³»ç»ŸçŠ¶æ€
        self.is_running = False
        self.last_update = None
    
    def _init_agent_system(self):
        """åˆå§‹åŒ–ä»£ç†ç³»ç»Ÿ"""
        try:
            # è·å–é…ç½®
            config = self.data_manager.config
            
            # æ£€æŸ¥ä»£ç†ç³»ç»Ÿæ˜¯å¦å¯ç”¨
            agent_system_config = config.get('agent_system', {})
            if not agent_system_config.get('enabled', False):
                logger.info("Agent system is disabled in configuration")
                self.message_queue = None
                self.analysis_agent = None
                return
            
            # åˆå§‹åŒ–æ¶ˆæ¯é˜Ÿåˆ—
            mq_config = config.get('message_queue', {})
            self.message_queue = MessageQueueManager(mq_config)
            logger.info("Message queue initialized")
            
            # åˆå§‹åŒ–åˆ†æä»£ç†
            analysis_enabled = config.get('ai_analysis', {}).get('analysis_agent', {}).get('enabled', False)
            if analysis_enabled:
                self.analysis_agent = AnalysisAgent(config, self.message_queue)
                logger.info("Analysis agent initialized")
            else:
                self.analysis_agent = None
                logger.info("Analysis agent is disabled")
                
        except Exception as e:
            logger.error(f"Failed to initialize agent system: {e}")
            self.message_queue = None
            self.analysis_agent = None
        
    def fetch_all_data(self):
        """è·å–æ‰€æœ‰æ—¶é—´å‘¨æœŸçš„æ•°æ®"""
        try:
            logger.info("Starting comprehensive data fetch...")
            
            # è·å–è´¦æˆ·ä¿¡æ¯
            account_summary = self.data_manager.get_account_summary()
            
            # è·å–å¸‚åœºä¿¡æ¯  
            market_summary = self.data_manager.get_market_summary()
            
            # è·å–å¹¶å¤„ç†æ‰€æœ‰æ—¶é—´å‘¨æœŸçš„Kçº¿æ•°æ®
            results = self.data_manager.fetch_and_process_kline_data()
            
            # è‡ªåŠ¨æˆæƒæ–°ç”Ÿæˆçš„æ–‡ä»¶ç»™MCPæœåŠ¡
            self._authorize_new_files(results)
            
            # ä¿å­˜è¿è¡Œæ‘˜è¦
            self._save_run_summary(results, account_summary, market_summary)
            
            # è§¦å‘åˆ†æè¯·æ±‚ï¼ˆå¦‚æœä»£ç†ç³»ç»Ÿå¯ç”¨ï¼‰
            self._trigger_analysis_if_enabled(results)
            
            self.last_update = datetime.utcnow()
            logger.info("Data fetch completed successfully")
            
            return results
            
        except Exception as e:
            logger.error(f"Error in fetch_all_data: {e}")
            return {'success': [], 'failed': [], 'error': str(e)}
    
    def _authorize_new_files(self, fetch_results):
        """è‡ªåŠ¨æˆæƒæ–°æ–‡ä»¶ç»™MCPæœåŠ¡"""
        try:
            from src.mcp_service import load_manifest, save_manifest
            
            manifest = load_manifest()
            current_files = set(manifest.get('files', []))
            new_files = []
            
            # æ”¶é›†æ‰€æœ‰æ–°ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
            for success_item in fetch_results.get('success', []):
                file_paths = success_item.get('file_paths', {})
                for file_type, file_path in file_paths.items():
                    if file_path:
                        # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                        try:
                            relative_path = str(Path(file_path).relative_to(Path("kline_data")))
                            if relative_path not in current_files:
                                new_files.append(relative_path)
                                current_files.add(relative_path)
                        except ValueError:
                            # å¦‚æœæ— æ³•è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ï¼Œè·³è¿‡
                            continue
            
            if new_files:
                manifest['files'] = sorted(list(current_files))
                save_manifest(manifest)
                logger.info(f"Auto-authorized {len(new_files)} new files for MCP access")
            
        except Exception as e:
            logger.warning(f"Failed to auto-authorize files: {e}")
    
    def _save_run_summary(self, fetch_results, account_summary, market_summary):
        """ä¿å­˜è¿è¡Œæ‘˜è¦"""
        try:
            summary = {
                'timestamp': datetime.utcnow().isoformat() + 'Z',
                'fetch_results': fetch_results,
                'account_summary': account_summary,
                'market_summary': market_summary,
                'system_status': {
                    'is_running': self.is_running,
                    'last_update': self.last_update.isoformat() + 'Z' if self.last_update else None
                }
            }
            
            summary_dir = Path('system_logs')
            summary_dir.mkdir(exist_ok=True)
            
            timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
            summary_file = summary_dir / f'run_summary_{timestamp_str}.json'
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"Run summary saved to: {summary_file}")
            
        except Exception as e:
            logger.error(f"Failed to save run summary: {e}")
    
    def setup_scheduler(self):
        """è®¾ç½®å®šæ—¶ä»»åŠ¡"""
        try:
            # æ¯å°æ—¶è·å–ä¸€æ¬¡æ•°æ®
            schedule.every().hour.do(self.fetch_all_data)
            
            # æ¯å¤©æ¸…ç†ä¸€æ¬¡æ—§æ–‡ä»¶
            schedule.every().day.at("02:00").do(self._cleanup_old_files)
            
            logger.info("Scheduler setup completed")
            
        except Exception as e:
            logger.error(f"Failed to setup scheduler: {e}")
    
    def _cleanup_old_files(self):
        """æ¸…ç†æ—§æ–‡ä»¶"""
        try:
            deleted_files = self.data_manager.cleanup_old_files(days_to_keep=7)
            logger.info(f"Cleanup completed: removed {len(deleted_files)} old files")
        except Exception as e:
            logger.error(f"Error during cleanup: {e}")
    
    def _trigger_analysis_if_enabled(self, data_results: Dict[str, Any]):
        """å¦‚æœä»£ç†ç³»ç»Ÿå¯ç”¨ï¼Œè§¦å‘åˆ†æè¯·æ±‚"""
        if not hasattr(self, 'message_queue') or not self.message_queue or not hasattr(self, 'analysis_agent') or not self.analysis_agent:
            return
        
        try:
            # æ„å»ºåˆ†æè§¦å‘æ•°æ®
            trigger_data = {
                "trigger_type": "data_update",
                "timestamp": datetime.utcnow().isoformat(),
                "data_summary": {
                    "successful_timeframes": len(data_results.get('success', [])),
                    "failed_timeframes": len(data_results.get('failed', [])),
                    "timeframes": [tf.get('timeframe') for tf in data_results.get('success', [])]
                }
            }
            
            # å‘å¸ƒåˆ†æè¯·æ±‚æ¶ˆæ¯
            topics = self.data_manager.config.get('message_queue', {}).get('topics', {})
            analysis_topic = topics.get('analysis_request', 'analysis.request')
            
            message_id = self.message_queue.publish(
                topic=analysis_topic,
                payload=trigger_data,
                sender="ai_trading_system"
            )
            
            logger.info(f"Published analysis request {message_id} after data update")
            
        except Exception as e:
            logger.error(f"Failed to trigger analysis: {e}")
    
    def start_agent_system(self):
        """å¯åŠ¨ä»£ç†ç³»ç»Ÿ"""
        if not hasattr(self, 'message_queue') or not self.message_queue:
            logger.info("Agent system not initialized, skipping start")
            return
        
        try:
            # å¯åŠ¨æ¶ˆæ¯é˜Ÿåˆ—
            self.message_queue.start()
            logger.info("Message queue started")
            
            # å¯åŠ¨åˆ†æä»£ç†
            if hasattr(self, 'analysis_agent') and self.analysis_agent:
                self.analysis_agent.start()
                logger.info("Analysis agent started")
            
            logger.info("Agent system started successfully")
            
        except Exception as e:
            logger.error(f"Failed to start agent system: {e}")
    
    def stop_agent_system(self):
        """åœæ­¢ä»£ç†ç³»ç»Ÿ"""
        if not hasattr(self, 'message_queue') or not self.message_queue:
            return
        
        try:
            # åœæ­¢åˆ†æä»£ç†
            if hasattr(self, 'analysis_agent') and self.analysis_agent:
                self.analysis_agent.stop()
                logger.info("Analysis agent stopped")
            
            # åœæ­¢æ¶ˆæ¯é˜Ÿåˆ—
            self.message_queue.stop()
            logger.info("Message queue stopped")
            
            logger.info("Agent system stopped successfully")
            
        except Exception as e:
            logger.error(f"Failed to stop agent system: {e}")
    
    def start_scheduler(self):
        """å¯åŠ¨å®šæ—¶ä»»åŠ¡"""
        logger.info("Starting scheduler...")
        self.is_running = True
        
        while self.is_running:
            try:
                schedule.run_pending()
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            except KeyboardInterrupt:
                logger.info("Scheduler stopped by user")
                self.is_running = False
                break
            except Exception as e:
                logger.error(f"Scheduler error: {e}")
                time.sleep(60)
    
    def run_once(self):
        """è¿è¡Œä¸€æ¬¡æ•°æ®è·å–"""
        logger.info("Running single data fetch...")
        return self.fetch_all_data()

def run_mcp_service():
    """è¿è¡ŒMCPæœåŠ¡"""
    import uvicorn
    logger.info("Starting MCP service on port 5000...")
    
    # ç¡®ä¿MCP APIå¯†é’¥å·²è®¾ç½®
    if not os.getenv('MCP_API_KEY'):
        logger.error("MCP_API_KEY not set!")
        return
    
    try:
        uvicorn.run(
            "main:mcp_app", 
            host="0.0.0.0", 
            port=5000, 
            log_level="info",
            reload=False
        )
    except Exception as e:
        logger.error(f"MCP service error: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("AI Trading System Starting...")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        trading_system = AITradingSystem()
        
        # è®¾ç½®å®šæ—¶ä»»åŠ¡
        trading_system.setup_scheduler()
        
        # å¯åŠ¨ä»£ç†ç³»ç»Ÿï¼ˆåœ¨æ•°æ®è·å–ä¹‹å‰ï¼Œé¿å…æ¶ˆæ¯ä¸¢å¤±ï¼‰
        print("\nğŸ¤– å¯åŠ¨AIä»£ç†ç³»ç»Ÿ...")
        trading_system.start_agent_system()
        
        # ç«‹å³è¿è¡Œä¸€æ¬¡æ•°æ®è·å–
        print("\nğŸ”„ æ‰§è¡Œåˆå§‹æ•°æ®è·å–...")
        initial_results = trading_system.run_once()
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        successful_timeframes = len(initial_results.get('success', []))
        failed_timeframes = len(initial_results.get('failed', []))
        print(f"âœ… æˆåŠŸå¤„ç† {successful_timeframes} ä¸ªæ—¶é—´å‘¨æœŸ")
        
        if failed_timeframes > 0:
            print(f"âŒ å¤±è´¥ {failed_timeframes} ä¸ªæ—¶é—´å‘¨æœŸ")
            for failed in initial_results.get('failed', []):
                print(f"   - {failed.get('timeframe')}: {failed.get('reason')}")
        
        # å¯åŠ¨MCPæœåŠ¡
        print("\nğŸš€ å¯åŠ¨MCPæœåŠ¡ (ç«¯å£ 5000)...")
        print("ğŸ“Š ç³»ç»Ÿå·²å°±ç»ª - AIç°åœ¨å¯ä»¥é€šè¿‡MCPè®¿é—®æ•°æ®")
        print("\n" + "=" * 60)
        print("ç³»ç»Ÿæ­£åœ¨è¿è¡Œ...")
        print("æŒ‰ Ctrl+C åœæ­¢")
        print("=" * 60)
        
        # åœ¨åå°è¿è¡Œå®šæ—¶ä»»åŠ¡
        with ThreadPoolExecutor(max_workers=3) as executor:
            # å¯åŠ¨å®šæ—¶ä»»åŠ¡
            scheduler_future = executor.submit(trading_system.start_scheduler)
            
            # å¯åŠ¨MCPæœåŠ¡ï¼ˆä¸»çº¿ç¨‹ï¼‰
            run_mcp_service()
        
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ç”¨æˆ·ç»ˆæ­¢ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
        logger.error(f"System error: {e}")
    finally:
        # åœæ­¢ä»£ç†ç³»ç»Ÿ
        try:
            trading_system.stop_agent_system()
        except:
            pass
        print("\nğŸ‘‹ AIäº¤æ˜“ç³»ç»Ÿå·²åœæ­¢")

if __name__ == "__main__":
    main()
