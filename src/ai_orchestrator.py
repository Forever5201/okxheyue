"""
AIäº¤æ˜“ç³»ç»Ÿç¼–æ’å™¨ V2.1 - é€’å½’å¼"æŒ‡æŒ¥å®˜-æ‰§è¡Œå®˜"æ¨¡å¼
AI Trading System Orchestrator V2.1 - Recursive "Commander-Executor" Pattern

å®ç°é€æ˜ã€å¯æ§çš„AIåˆ†æä»£ç†æ¶æ„ï¼š
- æŒ‡æŒ¥å®˜æ¨¡å¼ (main_session): ä»»åŠ¡åˆ†è§£å’Œæ•´ä½“è§„åˆ’
- åˆ†æå¸ˆæ¨¡å¼ (sub_session): å…·ä½“æ•°æ®åˆ†æå’Œæ‰§è¡Œ
"""

import json
import logging
import os
import requests
import pandas as pd
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Optional, Any, Union
from enum import Enum

from src.logger import setup_logger
from src.config_loader import ConfigLoader
from src.enhanced_data_manager import EnhancedDataManager

logger = setup_logger()

class SessionType(Enum):
    """ä¼šè¯ç±»å‹æšä¸¾"""
    MAIN_SESSION = "main_session"  # æŒ‡æŒ¥å®˜æ¨¡å¼
    SUB_SESSION = "sub_session"    # åˆ†æå¸ˆæ¨¡å¼

class ToolCategory(Enum):
    """å·¥å…·ç±»åˆ«æšä¸¾"""
    SIMPLE_TOOLS = "simple_tools"      # ç®€å•å·¥å…·ï¼šæ•°æ®è·å–
    META_TOOLS = "meta_tools"          # å…ƒå·¥å…·ï¼šä»»åŠ¡åˆ†è§£
    THINKING_TOOLS = "thinking_tools"  # æ€ç»´å·¥å…·ï¼šç»“æ„åŒ–æ€è€ƒ

@dataclass
class ToolCall:
    """å·¥å…·è°ƒç”¨è¯·æ±‚"""
    name: str
    parameters: Dict[str, Any]
    call_id: str = None

@dataclass  
class ToolResult:
    """å·¥å…·è°ƒç”¨ç»“æœ"""
    call_id: str
    success: bool
    data: Any = None
    error_message: str = None

@dataclass
class SessionConfig:
    """ä¼šè¯é…ç½®"""
    session_type: SessionType
    allowed_tool_categories: List[ToolCategory]
    max_iterations: int = 10
    enable_sequentialthinking: bool = True

class AIOrchestrator:
    """AIç¼–æ’å™¨ V2.1 - å®ç°é€’å½’å¼"æŒ‡æŒ¥å®˜-æ‰§è¡Œå®˜"æ¨¡å¼"""
    
    def __init__(self, data_manager: EnhancedDataManager, mcp_enabled: bool = False):
        """åˆå§‹åŒ–AIç¼–æ’å™¨"""
        # æ³¨å…¥ä¾èµ–
        self.data_manager = data_manager
        self.mcp_enabled = mcp_enabled
        
        # ä»data_managerè·å–é…ç½®
        self.config = self.data_manager.config
        
        # AIé…ç½®
        self.ai_config = self.config.get('ai_analysis', {}).get('qwen', {})
        self.api_key: Optional[str] = None
        self.base_url = self.ai_config.get('base_url', 'https://dashscope.aliyuncs.com/compatible-mode/v1')
        self.model = self.ai_config.get('model', 'qwen-plus')
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        self._load_configuration()
        
        # åˆå§‹åŒ–å·¥å…·ç³»ç»Ÿ
        self._initialize_tool_system()
        
        # åŠ è½½APIå‡­è¯
        self._load_api_credentials()
        
        # å½“å‰ä¼šè¯é…ç½®
        self.current_session_config = None
        
        # å¯¹è¯å†å²
        self.conversation_history = []
        
        logger.info("AIOrchestrator V2.1 åˆå§‹åŒ–å®Œæˆ")
    
    def _get_default_tool_classification(self) -> Dict:
        """è·å–é»˜è®¤å·¥å…·åˆ†ç±»é…ç½®"""
        return {
            "tool_classification_system": {
                "version": "2.1",
                "tool_categories": {
                    "simple_tools": {
                        "description": "åŸºç¡€æ•°æ®è·å–å’Œç®€å•è®¡ç®—å·¥å…·",
                        "allowed_sessions": ["main_session", "sub_session"],
                        "tools": {
                            "get_kline_data": {"description": "è·å–Kçº¿æ•°æ®"},
                            "get_market_ticker": {"description": "è·å–å¸‚åœºè¡Œæƒ…æ•°æ®"},
                            "get_latest_price": {"description": "è·å–æœ€æ–°ä»·æ ¼"}
                        }
                    },
                    "meta_tools": {
                        "description": "ä»»åŠ¡åˆ†è§£å’Œé«˜çº§ç¼–æ’å·¥å…·",
                        "allowed_sessions": ["main_session"],
                        "tools": {
                            "decompose_and_execute_task": {"description": "åˆ†è§£å¤æ‚ä»»åŠ¡å¹¶æ‰§è¡Œ"},
                            "analyze_complex_scenario": {"description": "å¤æ‚åœºæ™¯åˆ†æ"}
                        }
                    },
                    "thinking_tools": {
                        "description": "æ€ç»´å’Œæ¨ç†å·¥å…·",
                        "allowed_sessions": ["main_session", "sub_session"],
                        "tools": {
                            "sequentialthinking": {"description": "ç»“æ„åŒ–æ€ç»´æ¨ç†å·¥å…·"}
                        }
                    }
                },
                "session_configurations": {
                    "main_session": {
                        "allowed_tool_categories": ["simple_tools", "meta_tools", "thinking_tools"]
                    },
                    "sub_session": {
                        "allowed_tool_categories": ["simple_tools", "thinking_tools"]
                    }
                }
            }
        }
    
    def _load_configuration(self):
        """åŠ è½½V2.1é…ç½®æ–‡ä»¶"""
        try:
            # åŠ è½½å·¥å…·åˆ†ç±»é…ç½®
            tool_config_path = "config/tool_classification_config.json"
            if os.path.exists(tool_config_path):
                with open(tool_config_path, 'r', encoding='utf-8') as f:
                    self.tool_classification_config = json.load(f)
                logger.info("å·¥å…·åˆ†ç±»é…ç½®åŠ è½½æˆåŠŸ")
            else:
                self.tool_classification_config = self._get_default_tool_classification()
                logger.warning("å·¥å…·åˆ†ç±»é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            
            # åŠ è½½ç³»ç»Ÿæç¤ºè¯
            prompt_path = "config/AI_Trading_System_Prompt_V2.1.md"
            if os.path.exists(prompt_path):
                with open(prompt_path, 'r', encoding='utf-8') as f:
                    self.system_prompt = f.read()
            else:
                logger.warning(f"ç³»ç»Ÿæç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_path}")
                self.system_prompt = self._get_default_prompt()
            
            # åŠ è½½å·¥å…·é…ç½®
            tools_path = "config/AI_Trading_System_Tools_V2.1.json"
            if os.path.exists(tools_path):
                with open(tools_path, 'r', encoding='utf-8') as f:
                    self.tools_config = json.load(f)
            else:
                logger.warning(f"å·¥å…·é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {tools_path}")
                self.tools_config = self._get_default_tools_config()
                
        except Exception as e:
            logger.error(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            self.system_prompt = self._get_default_prompt()
            self.tools_config = self._get_default_tools_config()
    
    def _initialize_tool_system(self):
        """åˆå§‹åŒ–å·¥å…·ç³»ç»Ÿ"""
        # å·¥å…·é€‚é…å™¨æ˜ å°„
        self.tool_adapters = {
            # ç®€å•å·¥å…·
            'get_kline_data': self._get_kline_data_adapter,
            'get_market_ticker': self._get_market_ticker_adapter,
            'get_latest_price': self._get_latest_price_adapter,
            'get_account_balance': self._get_account_balance_adapter,
            'get_positions': self._get_positions_adapter,
            'calculate_risk_metrics': self._calculate_risk_metrics_adapter,
            
            # å…ƒå·¥å…·
            'decompose_and_execute_task': self._decompose_and_execute_task_adapter,
            
            # æ€ç»´å·¥å…·
            'sequentialthinking': self._sequentialthinking_adapter
        }
        
        # å·¥å…·åˆ†ç±»æ˜ å°„
        self.tool_categories = {
            ToolCategory.SIMPLE_TOOLS: [
                'get_kline_data', 'get_market_ticker', 'get_latest_price',
                'get_account_balance', 'get_positions', 'calculate_risk_metrics'
            ],
            ToolCategory.META_TOOLS: [
                'decompose_and_execute_task'
            ],
            ToolCategory.THINKING_TOOLS: [
                'sequentialthinking'
            ]
        }
        
        # ä¼šè¯å·¥å…·æƒé™é…ç½®
        self.session_tool_permissions = {
            SessionType.MAIN_SESSION: [
                ToolCategory.META_TOOLS,
                ToolCategory.THINKING_TOOLS
            ],
            SessionType.SUB_SESSION: [
                ToolCategory.SIMPLE_TOOLS,
                ToolCategory.THINKING_TOOLS
            ]
        }
    
    def _get_default_prompt(self) -> str:
        """è·å–é»˜è®¤ç³»ç»Ÿæç¤ºè¯"""
        return """# AIäº¤æ˜“ç³»ç»Ÿåˆ†æå¸ˆ V2.1

## è§’è‰²å®šä¹‰
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIäº¤æ˜“ç³»ç»Ÿåˆ†æå¸ˆï¼Œå…·å¤‡é€’å½’å¼"æŒ‡æŒ¥å®˜-æ‰§è¡Œå®˜"æ¨¡å¼çš„èƒ½åŠ›ã€‚

## æœ€é«˜æŒ‡ä»¤
é£é™©è§„é¿ä¼˜å…ˆï¼šåœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œé£é™©æ§åˆ¶éƒ½æ˜¯ç¬¬ä¸€ä¼˜å…ˆçº§ã€‚

## å·¥ä½œæ¨¡å¼è¯†åˆ«
æ ¹æ®å½“å‰ä¼šè¯ç±»å‹è‡ªåŠ¨åˆ‡æ¢å·¥ä½œæ¨¡å¼ï¼š
- æŒ‡æŒ¥å®˜æ¨¡å¼(main_session)ï¼šè´Ÿè´£ä»»åŠ¡åˆ†è§£å’Œæ•´ä½“è§„åˆ’
- åˆ†æå¸ˆæ¨¡å¼(sub_session)ï¼šè´Ÿè´£å…·ä½“æ•°æ®åˆ†æå’Œæ‰§è¡Œ

## æ ¸å¿ƒèƒ½åŠ›
1. å†³ç­–é€æ˜æ€§ï¼šæ¯ä¸ªå†³ç­–éƒ½æœ‰æ¸…æ™°çš„æ¨ç†è¿‡ç¨‹
2. è¡Œä¸ºå¯æ§æ€§ï¼šä¸¥æ ¼æŒ‰ç…§æƒé™å’Œè§„åˆ™æ‰§è¡Œ
3. åˆ†å±‚è§„åˆ’èƒ½åŠ›ï¼šå¤æ‚ä»»åŠ¡è‡ªåŠ¨åˆ†è§£
4. ç»“æ„åŒ–æ€è€ƒèƒ½åŠ›ï¼šä½¿ç”¨sequentialthinkingå·¥å…·è¿›è¡Œæ·±åº¦æ€è€ƒ
"""
    
    def _get_default_tools_config(self) -> Dict:
        """è·å–é»˜è®¤å·¥å…·é…ç½®"""
        return {
            "tool_categories": {
                "simple_tools": {
                    "description": "åŸºç¡€æ•°æ®è·å–å·¥å…·",
                    "tools": ["get_kline_data", "get_market_ticker", "get_latest_price"]
                },
                "meta_tools": {
                    "description": "ä»»åŠ¡åˆ†è§£å’Œç¼–æ’å·¥å…·", 
                    "tools": ["decompose_and_execute_task"]
                },
                "thinking_tools": {
                    "description": "ç»“æ„åŒ–æ€ç»´å·¥å…·",
                    "tools": ["sequentialthinking"]
                }
            },
            "session_permissions": {
                "main_session": ["meta_tools", "thinking_tools"],
                "sub_session": ["simple_tools", "thinking_tools"]
            },
            "tools": {
                "get_kline_data": {
                    "description": "è·å–Kçº¿æ•°æ®",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "symbol": {"type": "string"},
                            "timeframe": {"type": "string"},
                            "limit": {"type": "integer"}
                        }
                    }
                }
            }
        }
    
    def _load_api_credentials(self):
        """åŠ è½½APIå‡­è¯"""
        try:
            self.api_key = os.environ.get("DASHSCOPE_API_KEY")
            if not self.api_key:
                logger.warning("DASHSCOPE_API_KEY not found in environment variables")
        except Exception as e:
            logger.error(f"Failed to load API credentials: {e}")
    
    def set_session_config(self, session_type: SessionType, **kwargs):
        """è®¾ç½®ä¼šè¯é…ç½®"""
        allowed_categories = self.session_tool_permissions.get(session_type, [])
        
        self.current_session_config = SessionConfig(
            session_type=session_type,
            allowed_tool_categories=allowed_categories,
            max_iterations=kwargs.get('max_iterations', 10),
            enable_sequentialthinking=kwargs.get('enable_sequentialthinking', True)
        )
        
        logger.info(f"ä¼šè¯é…ç½®å·²è®¾ç½®: {session_type.value}, å…è®¸å·¥å…·ç±»åˆ«: {[cat.value for cat in allowed_categories]}")
    
    def _is_tool_allowed(self, tool_name: str) -> bool:
        """æ£€æŸ¥å·¥å…·æ˜¯å¦è¢«å½“å‰ä¼šè¯å…è®¸"""
        if not self.current_session_config:
            return False
        
        # ä»å·¥å…·åˆ†ç±»é…ç½®ä¸­è·å–ä¿¡æ¯
        tool_categories = self.tool_classification_config.get("tool_classification_system", {}).get("tool_categories", {})
        session_config = self.tool_classification_config.get("tool_classification_system", {}).get("session_configurations", {})
        
        # è·å–å½“å‰ä¼šè¯ç±»å‹
        current_session = self.current_session_config.session_type.value
        
        # è·å–å½“å‰ä¼šè¯å…è®¸çš„å·¥å…·ç±»åˆ«
        allowed_categories = session_config.get(current_session, {}).get("allowed_tool_categories", [])
        
        # æ£€æŸ¥å·¥å…·æ˜¯å¦åœ¨å…è®¸çš„ç±»åˆ«ä¸­
        for category_name in allowed_categories:
            if category_name in tool_categories:
                category_tools = tool_categories[category_name].get("tools", {})
                if tool_name in category_tools:
                    return True
        
        return False
    
    # å·¥å…·é€‚é…å™¨æ–¹æ³•
    def _get_kline_data_adapter(self, symbol=None, timeframe='1h', limit=100):
        """Kçº¿æ•°æ®è·å–é€‚é…å™¨"""
        try:
            if symbol is None:
                symbol = self.data_manager.trading_symbol
            
            result = self.data_manager.fetch_and_process_kline_data(
                symbol=symbol, 
                timeframes=[timeframe]
            )
            
            if 'processed_data' in result and timeframe in result['processed_data']:
                return result['processed_data'][timeframe]
            else:
                return {'error': 'No data available for specified timeframe'}
                
        except Exception as e:
            logger.error(f"Error in get_kline_data_adapter: {e}")
            return {'error': str(e)}
    
    def _get_market_ticker_adapter(self, symbol=None):
        """å¸‚åœºè¡Œæƒ…è·å–é€‚é…å™¨"""
        try:
            result = self.data_manager.get_market_summary(symbol)
            if 'market_data' in result:
                return result['market_data']
            else:
                return result
        except Exception as e:
            logger.error(f"Error in get_market_ticker_adapter: {e}")
            return {'error': str(e)}
    
    def _get_latest_price_adapter(self, symbol=None):
        """æœ€æ–°ä»·æ ¼è·å–é€‚é…å™¨"""
        try:
            result = self.data_manager.get_market_summary(symbol)
            if 'market_data' in result and 'last' in result['market_data']:
                return {'price': result['market_data']['last'], 'symbol': symbol or self.data_manager.trading_symbol}
            else:
                return {'error': 'Price data not available'}
        except Exception as e:
            logger.error(f"Error in get_latest_price_adapter: {e}")
            return {'error': str(e)}
    
    def _get_account_balance_adapter(self):
        """è´¦æˆ·ä½™é¢è·å–é€‚é…å™¨"""
        try:
            result = self.data_manager.get_account_summary()
            if 'balance' in result:
                return result['balance']
            else:
                return result
        except Exception as e:
            logger.error(f"Error in get_account_balance_adapter: {e}")
            return {'error': str(e)}
    
    def _get_positions_adapter(self):
        """æŒä»“ä¿¡æ¯è·å–é€‚é…å™¨"""
        try:
            result = self.data_manager.get_account_summary()
            if 'positions' in result:
                return result['positions']
            else:
                return []
        except Exception as e:
            logger.error(f"Error in get_positions_adapter: {e}")
            return {'error': str(e)}
    
    def _calculate_risk_metrics_adapter(self):
        """é£é™©æŒ‡æ ‡è®¡ç®—é€‚é…å™¨"""
        try:
            account_data = self.data_manager.get_account_summary()
            market_data = self.data_manager.get_market_summary()
            
            risk_metrics = {
                'account_balance': account_data.get('balance', {}).get('balance', 0),
                'available_balance': account_data.get('balance', {}).get('available_balance', 0),
                'positions_count': len(account_data.get('positions', [])),
                'market_price': market_data.get('market_data', {}).get('last', 0),
                'timestamp': datetime.utcnow().isoformat() + 'Z'
            }
            
            return risk_metrics
        except Exception as e:
            logger.error(f"Error in calculate_risk_metrics_adapter: {e}")
            return {'error': str(e)}
    
    def _decompose_and_execute_task_adapter(self, task_description: str, context: Optional[Dict] = None):
        """ä»»åŠ¡åˆ†è§£å’Œæ‰§è¡Œé€‚é…å™¨"""
        try:
            # åˆ›å»ºå­ä¼šè¯æ¥æ‰§è¡Œåˆ†è§£åçš„ä»»åŠ¡
            sub_result = self.analyze_market(
                analysis_request=task_description,
                context=context,
                session_type=SessionType.SUB_SESSION
            )
            
            return {
                'task_decomposition': f"ä»»åŠ¡å·²åˆ†è§£å¹¶æ‰§è¡Œ: {task_description}",
                'sub_session_result': sub_result,
                'timestamp': datetime.utcnow().isoformat() + 'Z'
            }
        except Exception as e:
            logger.error(f"Error in decompose_and_execute_task_adapter: {e}")
            return {'error': str(e)}
    
    def _sequentialthinking_adapter(self, thinking_request: str, context: Optional[Dict] = None):
        """ç»“æ„åŒ–æ€ç»´é€‚é…å™¨ - å®ç°æ€è€ƒ-è¡ŒåŠ¨å¾ªç¯æ¨¡å¼"""
        try:
            # åˆå§‹åŒ–æ€è€ƒä¼šè¯
            thinking_session = {
                'session_id': f"thinking_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}",
                'request': thinking_request,
                'context': context or {},
                'thinking_steps': [],
                'actions_taken': [],
                'current_step': 1,
                'max_steps': 10,
                'status': 'active'
            }
            
            logger.info(f"å¯åŠ¨sequentialthinkingä¼šè¯: {thinking_session['session_id']}")
            
            # æ€è€ƒ-è¡ŒåŠ¨å¾ªç¯
            while thinking_session['current_step'] <= thinking_session['max_steps'] and thinking_session['status'] == 'active':
                step_result = self._execute_thinking_step(thinking_session)
                thinking_session['thinking_steps'].append(step_result)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œè¡ŒåŠ¨
                if step_result.get('requires_action', False):
                    action_result = self._execute_thinking_action(step_result, thinking_session)
                    thinking_session['actions_taken'].append(action_result)
                    
                    # æ›´æ–°ä¸Šä¸‹æ–‡
                    thinking_session['context'].update(action_result.get('context_updates', {}))
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆæ€è€ƒ
                if step_result.get('thinking_complete', False):
                    thinking_session['status'] = 'completed'
                    break
                
                thinking_session['current_step'] += 1
            
            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            final_result = self._synthesize_thinking_results(thinking_session)
            
            logger.info(f"sequentialthinkingä¼šè¯å®Œæˆ: {thinking_session['session_id']}, æ­¥éª¤æ•°: {len(thinking_session['thinking_steps'])}")
            
            return final_result
            
        except Exception as e:
            logger.error(f"Error in sequentialthinking_adapter: {e}")
            return {'error': str(e), 'session_id': thinking_session.get('session_id', 'unknown')}
    
    def _execute_thinking_step(self, thinking_session: Dict) -> Dict:
        """æ‰§è¡Œå•ä¸ªæ€è€ƒæ­¥éª¤"""
        try:
            step_num = thinking_session['current_step']
            request = thinking_session['request']
            context = thinking_session['context']
            
            # æ„å»ºæ€è€ƒæç¤º
            thinking_prompt = self._build_thinking_prompt(step_num, request, context, thinking_session['thinking_steps'])
            
            # æ¨¡æ‹Ÿç»“æ„åŒ–æ€è€ƒè¿‡ç¨‹
            step_result = {
                'step_number': step_num,
                'timestamp': datetime.utcnow().isoformat() + 'Z',
                'thinking_focus': self._determine_thinking_focus(step_num, request),
                'analysis': self._perform_step_analysis(thinking_prompt, context),
                'insights': [],
                'requires_action': False,
                'thinking_complete': False,
                'confidence_level': 0.0
            }
            
            # æ ¹æ®æ­¥éª¤ç±»å‹è¿›è¡Œä¸åŒçš„æ€è€ƒ
            if step_num == 1:
                step_result.update(self._initial_problem_analysis(request, context))
            elif step_num <= 3:
                step_result.update(self._data_gathering_analysis(request, context))
            elif step_num <= 6:
                step_result.update(self._logical_reasoning_analysis(request, context, thinking_session['thinking_steps']))
            else:
                step_result.update(self._synthesis_analysis(request, context, thinking_session['thinking_steps']))
            
            return step_result
            
        except Exception as e:
            logger.error(f"Error in thinking step {thinking_session['current_step']}: {e}")
            return {
                'step_number': thinking_session['current_step'],
                'error': str(e),
                'thinking_complete': True
            }
    
    def _execute_thinking_action(self, step_result: Dict, thinking_session: Dict) -> Dict:
        """æ‰§è¡Œæ€è€ƒæ­¥éª¤ä¸­éœ€è¦çš„è¡ŒåŠ¨"""
        try:
            action_type = step_result.get('action_type', 'data_collection')
            action_params = step_result.get('action_params', {})
            
            action_result = {
                'action_type': action_type,
                'step_number': step_result['step_number'],
                'timestamp': datetime.utcnow().isoformat() + 'Z',
                'success': False,
                'data': None,
                'context_updates': {}
            }
            
            # æ ¹æ®è¡ŒåŠ¨ç±»å‹æ‰§è¡Œç›¸åº”æ“ä½œ
            if action_type == 'data_collection':
                action_result.update(self._execute_data_collection_action(action_params))
            elif action_type == 'analysis_verification':
                action_result.update(self._execute_verification_action(action_params, thinking_session))
            elif action_type == 'pattern_recognition':
                action_result.update(self._execute_pattern_recognition_action(action_params))
            else:
                action_result['data'] = f"æœªçŸ¥è¡ŒåŠ¨ç±»å‹: {action_type}"
            
            return action_result
            
        except Exception as e:
            logger.error(f"Error executing thinking action: {e}")
            return {
                'action_type': step_result.get('action_type', 'unknown'),
                'error': str(e),
                'success': False
            }
    
    def _synthesize_thinking_results(self, thinking_session: Dict) -> Dict:
        """ç»¼åˆæ€è€ƒç»“æœ"""
        try:
            thinking_steps = thinking_session['thinking_steps']
            actions_taken = thinking_session['actions_taken']
            
            # æå–å…³é”®æ´å¯Ÿ
            key_insights = []
            for step in thinking_steps:
                key_insights.extend(step.get('insights', []))
            
            # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
            confidence_scores = [step.get('confidence_level', 0.0) for step in thinking_steps if 'confidence_level' in step]
            overall_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0
            
            # ç”Ÿæˆæœ€ç»ˆç»“è®º
            final_conclusion = self._generate_final_conclusion(thinking_steps, actions_taken, thinking_session['request'])
            
            return {
                'session_id': thinking_session['session_id'],
                'original_request': thinking_session['request'],
                'thinking_process': {
                    'total_steps': len(thinking_steps),
                    'actions_taken': len(actions_taken),
                    'thinking_steps': thinking_steps,
                    'actions': actions_taken
                },
                'key_insights': key_insights,
                'final_conclusion': final_conclusion,
                'confidence_level': overall_confidence,
                'recommendations': self._generate_recommendations(thinking_steps, actions_taken),
                'context_enrichment': thinking_session['context'],
                'timestamp': datetime.utcnow().isoformat() + 'Z',
                'status': thinking_session['status']
            }
            
        except Exception as e:
            logger.error(f"Error synthesizing thinking results: {e}")
            return {
                'session_id': thinking_session.get('session_id', 'unknown'),
                'error': str(e),
                'status': 'error'
            }
    
    def _build_thinking_prompt(self, step_num: int, request: str, context: Dict, previous_steps: List[Dict]) -> str:
        """æ„å»ºæ€è€ƒæç¤º"""
        base_prompt = f"æ­¥éª¤ {step_num}: é’ˆå¯¹è¯·æ±‚ '{request}' è¿›è¡Œç»“æ„åŒ–æ€è€ƒ"
        
        if previous_steps:
            previous_insights = []
            for step in previous_steps[-3:]:  # åªè€ƒè™‘æœ€è¿‘3æ­¥
                previous_insights.extend(step.get('insights', []))
            
            if previous_insights:
                base_prompt += f"\nå‰æœŸæ´å¯Ÿ: {'; '.join(previous_insights[-5:])}"  # æœ€è¿‘5ä¸ªæ´å¯Ÿ
        
        return base_prompt
    
    def _determine_thinking_focus(self, step_num: int, request: str) -> str:
        """ç¡®å®šæ€è€ƒç„¦ç‚¹"""
        focus_map = {
            1: "é—®é¢˜ç†è§£ä¸åˆ†è§£",
            2: "æ•°æ®éœ€æ±‚è¯†åˆ«", 
            3: "ä¿¡æ¯æ”¶é›†ç­–ç•¥",
            4: "é€»è¾‘æ¨ç†æ¡†æ¶",
            5: "æ¨¡å¼è¯†åˆ«åˆ†æ",
            6: "å‡è®¾éªŒè¯",
            7: "ç»“è®ºç»¼åˆ",
            8: "é£é™©è¯„ä¼°",
            9: "å»ºè®®ç”Ÿæˆ",
            10: "æœ€ç»ˆéªŒè¯"
        }
        return focus_map.get(step_num, f"æ·±åº¦åˆ†æ-æ­¥éª¤{step_num}")
    
    def _perform_step_analysis(self, prompt: str, context: Dict) -> str:
        """æ‰§è¡Œæ­¥éª¤åˆ†æ"""
        # è¿™é‡Œå¯ä»¥é›†æˆçœŸå®çš„AIæ¨ç†
        # ç›®å‰è¿”å›æ¨¡æ‹Ÿåˆ†æ
        return f"åŸºäºæç¤º '{prompt}' å’Œä¸Šä¸‹æ–‡è¿›è¡Œçš„ç»“æ„åŒ–åˆ†æ"
    
    def _initial_problem_analysis(self, request: str, context: Dict) -> Dict:
        """åˆå§‹é—®é¢˜åˆ†æ"""
        return {
            'insights': [f"è¯†åˆ«æ ¸å¿ƒé—®é¢˜: {request}", "ç¡®å®šåˆ†æç»´åº¦", "è¯„ä¼°å¤æ‚åº¦"],
            'requires_action': True,
            'action_type': 'data_collection',
            'action_params': {'focus': 'problem_scope'},
            'confidence_level': 0.7
        }
    
    def _data_gathering_analysis(self, request: str, context: Dict) -> Dict:
        """æ•°æ®æ”¶é›†åˆ†æ"""
        return {
            'insights': ["è¯†åˆ«æ•°æ®éœ€æ±‚", "ç¡®å®šä¿¡æ¯æ¥æº", "è¯„ä¼°æ•°æ®è´¨é‡"],
            'requires_action': True,
            'action_type': 'data_collection',
            'action_params': {'focus': 'market_data'},
            'confidence_level': 0.8
        }
    
    def _logical_reasoning_analysis(self, request: str, context: Dict, previous_steps: List[Dict]) -> Dict:
        """é€»è¾‘æ¨ç†åˆ†æ"""
        return {
            'insights': ["æ„å»ºæ¨ç†é“¾æ¡", "éªŒè¯é€»è¾‘ä¸€è‡´æ€§", "è¯†åˆ«å…³é”®æ¨¡å¼"],
            'requires_action': True,
            'action_type': 'pattern_recognition',
            'action_params': {'focus': 'logical_patterns'},
            'confidence_level': 0.85
        }
    
    def _synthesis_analysis(self, request: str, context: Dict, previous_steps: List[Dict]) -> Dict:
        """ç»¼åˆåˆ†æ"""
        return {
            'insights': ["æ•´åˆåˆ†æç»“æœ", "å½¢æˆæœ€ç»ˆç»“è®º", "è¯„ä¼°ç½®ä¿¡åº¦"],
            'requires_action': False,
            'thinking_complete': True,
            'confidence_level': 0.9
        }
    
    def _execute_data_collection_action(self, params: Dict) -> Dict:
        """æ‰§è¡Œæ•°æ®æ”¶é›†è¡ŒåŠ¨"""
        focus = params.get('focus', 'general')
        return {
            'success': True,
            'data': f"æ”¶é›†åˆ°å…³äº {focus} çš„ç›¸å…³æ•°æ®",
            'context_updates': {f'{focus}_data_collected': True}
        }
    
    def _execute_verification_action(self, params: Dict, thinking_session: Dict) -> Dict:
        """æ‰§è¡ŒéªŒè¯è¡ŒåŠ¨"""
        return {
            'success': True,
            'data': "éªŒè¯åˆ†æç»“æœçš„ä¸€è‡´æ€§å’Œé€»è¾‘æ€§",
            'context_updates': {'verification_completed': True}
        }
    
    def _execute_pattern_recognition_action(self, params: Dict) -> Dict:
        """æ‰§è¡Œæ¨¡å¼è¯†åˆ«è¡ŒåŠ¨"""
        focus = params.get('focus', 'general_patterns')
        return {
            'success': True,
            'data': f"è¯†åˆ«åˆ° {focus} ä¸­çš„å…³é”®æ¨¡å¼",
            'context_updates': {f'{focus}_patterns_identified': True}
        }
    
    def _generate_final_conclusion(self, thinking_steps: List[Dict], actions_taken: List[Dict], original_request: str) -> str:
        """ç”Ÿæˆæœ€ç»ˆç»“è®º"""
        step_count = len(thinking_steps)
        action_count = len(actions_taken)
        
        return f"ç»è¿‡ {step_count} æ­¥ç»“æ„åŒ–æ€è€ƒå’Œ {action_count} æ¬¡è¡ŒåŠ¨éªŒè¯ï¼Œé’ˆå¯¹ '{original_request}' çš„åˆ†æå·²å®Œæˆã€‚æ•´åˆäº†å¤šç»´åº¦æ´å¯Ÿï¼Œå½¢æˆäº†ç³»ç»Ÿæ€§çš„ç†è§£å’Œå»ºè®®ã€‚"
    
    def _generate_recommendations(self, thinking_steps: List[Dict], actions_taken: List[Dict]) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = [
            "åŸºäºç»“æ„åŒ–æ€è€ƒè¿‡ç¨‹çš„å»ºè®®",
            "è€ƒè™‘å¤šç»´åº¦åˆ†æç»“æœ",
            "å»ºè®®é‡‡ç”¨æ¸è¿›å¼å®æ–½ç­–ç•¥"
        ]
        
        # æ ¹æ®æ€è€ƒæ­¥éª¤æ·»åŠ å…·ä½“å»ºè®®
        if len(thinking_steps) >= 5:
            recommendations.append("æ·±åº¦åˆ†æå·²å®Œæˆï¼Œå»ºè®®é‡ç‚¹å…³æ³¨å…³é”®æ´å¯Ÿ")
        
        if len(actions_taken) >= 3:
            recommendations.append("å¤šæ¬¡éªŒè¯ç¡®ä¿äº†ç»“è®ºçš„å¯é æ€§")
        
        return recommendations
    
    def execute_tool_call(self, tool_call: ToolCall) -> ToolResult:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        try:
            # æ£€æŸ¥å·¥å…·æƒé™
            if not self._is_tool_allowed(tool_call.name):
                return ToolResult(
                    call_id=tool_call.call_id,
                    success=False,
                    error_message=f"å·¥å…· {tool_call.name} ä¸åœ¨å½“å‰ä¼šè¯æƒé™å†…"
                )
            
            # è·å–å·¥å…·é€‚é…å™¨
            if tool_call.name not in self.tool_adapters:
                return ToolResult(
                    call_id=tool_call.call_id,
                    success=False,
                    error_message=f"æœªçŸ¥å·¥å…·: {tool_call.name}"
                )
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            adapter = self.tool_adapters[tool_call.name]
            result = adapter(**tool_call.parameters)
            
            return ToolResult(
                call_id=tool_call.call_id,
                success=True,
                data=result
            )
            
        except Exception as e:
            logger.error(f"å·¥å…·è°ƒç”¨æ‰§è¡Œå¤±è´¥: {tool_call.name} - {e}")
            return ToolResult(
                call_id=tool_call.call_id,
                success=False,
                error_message=str(e)
            )
    
    def send_ai_request(self, messages: List[Dict], tools: Optional[List[Dict]] = None) -> Dict:
        """å‘é€AIè¯·æ±‚"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": self.model,
                "messages": messages,
                "temperature": 0.1,
                "max_tokens": 2000
            }
            
            if tools:
                payload["tools"] = tools
                payload["tool_choice"] = "auto"
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            response.raise_for_status()
            return response.json()
            
        except Exception as e:
            logger.error(f"AIè¯·æ±‚å¤±è´¥: {e}")
            return {
                "choices": [{
                    "message": {
                        "role": "assistant",
                        "content": f"AIè¯·æ±‚å¤±è´¥: {str(e)}"
                    }
                }]
            }
    
    def analyze_market(self, analysis_request: str, context: Optional[Dict] = None, session_type: SessionType = SessionType.MAIN_SESSION) -> Dict:
        """
        æ‰§è¡Œå¸‚åœºåˆ†æ - æ”¯æŒé€’å½’å¼ä¼šè¯ç®¡ç†
        
        Args:
            analysis_request: åˆ†æè¯·æ±‚
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            session_type: ä¼šè¯ç±»å‹
            
        Returns:
            åˆ†æç»“æœ
        """
        try:
            # è®¾ç½®ä¼šè¯é…ç½®
            self.set_session_config(session_type)
            
            # åˆ¤æ–­ä»»åŠ¡å¤æ‚åº¦
            complexity = self._assess_task_complexity(analysis_request)
            
            if complexity == "complex" and session_type == SessionType.MAIN_SESSION:
                # å¤æ‚ä»»åŠ¡ï¼šä½¿ç”¨æŒ‡æŒ¥å®˜æ¨¡å¼è¿›è¡Œä»»åŠ¡åˆ†è§£
                return self._execute_commander_mode(analysis_request, context)
            else:
                # ç®€å•ä»»åŠ¡ï¼šç›´æ¥æ‰§è¡Œåˆ†æå¸ˆæ¨¡å¼
                return self._execute_analyst_mode(analysis_request, context)
                
        except Exception as e:
            logger.error(f"å¸‚åœºåˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis": None,
                "execution_log": [f"âŒ åˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}"],
                "timestamp": datetime.utcnow().isoformat() + 'Z'
            }
    
    def _assess_task_complexity(self, request: str) -> str:
        """è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦"""
        complex_keywords = [
            "ç»¼åˆåˆ†æ", "å…¨é¢è¯„ä¼°", "å¤šç»´åº¦", "æ·±åº¦åˆ†æ", 
            "ç­–ç•¥åˆ¶å®š", "é£é™©è¯„ä¼°", "æŠ•èµ„å»ºè®®"
        ]
        
        simple_keywords = [
            "è·å–", "æŸ¥è¯¢", "æ˜¾ç¤º", "å½“å‰ä»·æ ¼", "æœ€æ–°æ•°æ®"
        ]
        
        request_lower = request.lower()
        
        if any(keyword in request_lower for keyword in complex_keywords):
            return "complex"
        elif any(keyword in request_lower for keyword in simple_keywords):
            return "simple"
        else:
            return "medium"
    
    def _execute_commander_mode(self, request: str, context: Optional[Dict] = None) -> Dict:
        """æ‰§è¡ŒæŒ‡æŒ¥å®˜æ¨¡å¼ - ä»»åŠ¡åˆ†è§£å’Œå­ä¼šè¯ç®¡ç†"""
        logger.info("ğŸ¯ å¯åŠ¨æŒ‡æŒ¥å®˜æ¨¡å¼")
        
        # æ„å»ºæŒ‡æŒ¥å®˜æ¨¡å¼çš„ç³»ç»Ÿæ¶ˆæ¯
        system_message = {
            "role": "system",
            "content": f"{self.system_prompt}\n\nå½“å‰æ¨¡å¼ï¼šæŒ‡æŒ¥å®˜æ¨¡å¼\nå¯ç”¨å·¥å…·ï¼šä»»åŠ¡åˆ†è§£å·¥å…·ã€æ€ç»´å·¥å…·"
        }
        
        user_message = {
            "role": "user",
            "content": f"è¯·åˆ†è§£ä»¥ä¸‹å¤æ‚ä»»åŠ¡ï¼š{request}"
        }
        
        if context:
            user_message["content"] += f"\n\nä¸Šä¸‹æ–‡ï¼š{json.dumps(context, ensure_ascii=False, indent=2)}"
        
        messages = [system_message, user_message]
        
        # è·å–æŒ‡æŒ¥å®˜æ¨¡å¼å¯ç”¨å·¥å…·
        available_tools = self._get_available_tools_for_session(SessionType.MAIN_SESSION)
        
        # æ‰§è¡Œå¤šè½®å¯¹è¯
        return self._execute_conversation_loop(messages, available_tools, "æŒ‡æŒ¥å®˜æ¨¡å¼")
    
    def _execute_analyst_mode(self, request: str, context: Optional[Dict] = None) -> Dict:
        """æ‰§è¡Œåˆ†æå¸ˆæ¨¡å¼ - å…·ä½“æ•°æ®åˆ†æ"""
        logger.info("ğŸ“Š å¯åŠ¨åˆ†æå¸ˆæ¨¡å¼")
        
        # æ„å»ºåˆ†æå¸ˆæ¨¡å¼çš„ç³»ç»Ÿæ¶ˆæ¯
        system_message = {
            "role": "system", 
            "content": f"{self.system_prompt}\n\nå½“å‰æ¨¡å¼ï¼šåˆ†æå¸ˆæ¨¡å¼\nå¯ç”¨å·¥å…·ï¼šæ•°æ®è·å–å·¥å…·ã€æ€ç»´å·¥å…·"
        }
        
        user_message = {
            "role": "user",
            "content": f"åˆ†æè¯·æ±‚ï¼š{request}"
        }
        
        if context:
            user_message["content"] += f"\n\nä¸Šä¸‹æ–‡ï¼š{json.dumps(context, ensure_ascii=False, indent=2)}"
        
        messages = [system_message, user_message]
        
        # è·å–åˆ†æå¸ˆæ¨¡å¼å¯ç”¨å·¥å…·
        available_tools = self._get_available_tools_for_session(SessionType.SUB_SESSION)
        
        # æ‰§è¡Œå¤šè½®å¯¹è¯
        return self._execute_conversation_loop(messages, available_tools, "åˆ†æå¸ˆæ¨¡å¼")
    
    def _get_available_tools_for_session(self, session_type: SessionType) -> List[Dict]:
        """è·å–æŒ‡å®šä¼šè¯ç±»å‹çš„å¯ç”¨å·¥å…·"""
        allowed_categories = self.session_tool_permissions.get(session_type, [])
        available_tools = []
        
        for category in allowed_categories:
            tools_in_category = self.tool_categories.get(category, [])
            for tool_name in tools_in_category:
                if tool_name in self.tools_config.get("tools", {}):
                    tool_def = self.tools_config["tools"][tool_name]
                    available_tools.append({
                        "type": "function",
                        "function": {
                            "name": tool_name,
                            "description": tool_def.get("description", ""),
                            "parameters": tool_def.get("parameters", {})
                        }
                    })
        
        return available_tools
    
    def _execute_conversation_loop(self, messages: List[Dict], available_tools: List[Dict], mode_name: str) -> Dict:
        """æ‰§è¡Œå¯¹è¯å¾ªç¯"""
        analysis_log = [f"ğŸš€ å¯åŠ¨{mode_name}"]
        max_iterations = self.current_session_config.max_iterations if self.current_session_config else 10
        iteration = 0
        
        while iteration < max_iterations:
            iteration += 1
            analysis_log.append(f"--- ç¬¬{iteration}è½®å¯¹è¯ ---")
            
            # å‘é€è¯·æ±‚ç»™AI
            ai_response = self.send_ai_request(messages, available_tools)
            
            # è§£æAIå“åº”
            message = ai_response['choices'][0]['message']
            messages.append(message)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            tool_calls = message.get('tool_calls', [])
            
            if not tool_calls:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œåˆ†æå®Œæˆ
                analysis_log.append(f"âœ… {mode_name}å®Œæˆï¼Œæ²¡æœ‰æ›´å¤šå·¥å…·è°ƒç”¨")
                break
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            tool_results = []
            for tool_call in tool_calls:
                function_call = tool_call['function']
                
                # åˆ›å»ºå·¥å…·è°ƒç”¨å¯¹è±¡
                call_request = ToolCall(
                    name=function_call['name'],
                    parameters=json.loads(function_call['arguments']),
                    call_id=tool_call['id']
                )
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                result = self.execute_tool_call(call_request)
                tool_results.append(result)
                
                # è®°å½•åˆ°åˆ†ææ—¥å¿—
                if result.success:
                    analysis_log.append(f"ğŸ”§ å·¥å…·è°ƒç”¨æˆåŠŸ: {call_request.name}")
                else:
                    analysis_log.append(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {call_request.name} - {result.error_message}")
            
            # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
            for tool_call, result in zip(tool_calls, tool_results):
                payload_content = result.data if result.success else {"error": result.error_message}
                tool_message = {
                    "role": "tool",
                    "tool_call_id": tool_call['id'],
                    "content": json.dumps(payload_content, ensure_ascii=False)
                }
                messages.append(tool_message)
        
        # è¿”å›æœ€ç»ˆç»“æœ
        final_response = messages[-1]['content'] if messages[-1]['role'] == 'assistant' else "åˆ†ææœªå®Œæˆ"
        
        return {
            "success": True,
            "analysis": final_response,
            "execution_log": analysis_log,
            "iterations": iteration,
            "session_type": self.current_session_config.session_type.value if self.current_session_config else "unknown",
            "timestamp": datetime.utcnow().isoformat() + 'Z'
        }
    
    def get_analysis_status(self) -> Dict:
        """è·å–åˆ†æç³»ç»ŸçŠ¶æ€"""
        return {
            "orchestrator_version": "2.1",
            "current_session": self.current_session_config.session_type.value if self.current_session_config else None,
            "allowed_tools": [cat.value for cat in self.current_session_config.allowed_tool_categories] if self.current_session_config else [],
            "api_configured": bool(self.api_key),
            "data_manager_ready": bool(self.data_manager),
            "timestamp": datetime.utcnow().isoformat() + 'Z'
        }

# ä¾¿åˆ©å‡½æ•°
def create_orchestrator(data_manager: EnhancedDataManager, mcp_enabled: bool = False) -> AIOrchestrator:
    """åˆ›å»ºAIç¼–æ’å™¨å®ä¾‹"""
    return AIOrchestrator(data_manager, mcp_enabled)

def quick_analysis(request: str, data_manager: EnhancedDataManager, context: Optional[Dict] = None) -> Dict:
    """å¿«é€Ÿåˆ†æä¾¿åˆ©å‡½æ•°"""
    orchestrator = create_orchestrator(data_manager)
    return orchestrator.analyze_market(request, context)