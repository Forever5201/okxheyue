"""
AIäº¤æ˜“ç³»ç»Ÿç¼–æ’å™¨ - é¡¹ç›®ç»ç†æ¨¡å¼
AI Trading System Orchestrator - Project Manager Pattern

å®ç°é€æ˜ã€å¯æ§çš„AIåˆ†æä»£ç†æ¶æ„ï¼š
- é¡¹ç›®ç»ç† (Pythonä»£ç ): ç®¡ç†æ•´ä¸ªæµç¨‹ï¼Œæ§åˆ¶èŠ‚å¥ï¼ŒéªŒè¯ç»“æœ
- AIåˆ†æå¸ˆ (AIæ¨¡å‹): åœ¨å®‰å…¨ç¯å¢ƒä¸­æ€è€ƒï¼Œå‘é¡¹ç›®ç»ç†è¯·æ±‚æ•°æ®å’Œå·¥å…·
"""

import json
import logging
import os
import time
import uuid
import requests
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

from src.logger import setup_logger
from src.config_loader import ConfigLoader

logger = setup_logger()

@dataclass
class ToolCall:
    """å·¥å…·è°ƒç”¨è¯·æ±‚"""
    name: str
    parameters: Dict[str, Any]
    call_id: str = None

@dataclass  
class ToolResult:
    """å·¥å…·è°ƒç”¨ç»“æœ"""
    call_id: str
    success: bool
    data: Any = None
    error_message: str = None
    name: Optional[str] = None
    parameters: Optional[Dict[str, Any]] = None
    latency_ms: Optional[float] = None
    status_code: Optional[int] = None

class AIOrchestrator:
    """
    AIç³»ç»Ÿç¼–æ’å™¨ - é¡¹ç›®ç»ç†æ¨¡å¼
    
    èŒè´£ï¼š
    1. åŠ è½½AIè¡Œä¸ºå‡†åˆ™å’Œå·¥å…·å®šä¹‰
    2. ç®¡ç†ä¸AIæ¨¡å‹çš„å¯¹è¯å¾ªç¯
    3. ç¿»è¯‘AIå·¥å…·è¯·æ±‚åˆ°æœ¬åœ°MCPæœåŠ¡è°ƒç”¨
    4. éªŒè¯å’Œå®¡æ ¸AIçš„åˆ†æç»“æœ
    """
    
    def __init__(self, config_path="config/enhanced_config.yaml"):
        """
        åˆå§‹åŒ–AIç¼–æ’å™¨
        
        Args:
            config_path: ä¸»é…ç½®æ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½ç³»ç»Ÿé…ç½®
        self.config_loader = ConfigLoader(config_path)
        self.config = self.config_loader.load_config()
        
        # AIé…ç½®
        self.ai_config = self.config.get('ai_analysis', {}).get('qwen', {})
        self.api_key: Optional[str] = None  # å°†ä»ç¯å¢ƒå˜é‡åŠ è½½
        self.base_url = self.ai_config.get('base_url', 'https://dashscope.aliyuncs.com/compatible-mode/v1')
        self.model = self.ai_config.get('model', 'qwen-plus')
        
        # MCPæœåŠ¡é…ç½®
        self.mcp_config = self.config.get('mcp_service', {})
        self.mcp_host = self.mcp_config.get('host', 'localhost')
        self.mcp_port = self.mcp_config.get('port', 5000)
        self.mcp_api_key: Optional[str] = None  # å°†ä»ç¯å¢ƒå˜é‡åŠ è½½
        
        # åˆ†æä»£ç†é¢„ç®—ä¸çº¦æŸé…ç½®
        self.agent_config = self.config.get('ai_analysis', {}).get('analysis_agent', {})
        self.max_tool_calls = int(self.agent_config.get('max_tool_calls', 20))
        self.analysis_timeout_seconds = int(self.agent_config.get('analysis_timeout', 300))
        self.observability = self.agent_config.get('observability', {})
        self.log_prompt_meta: bool = bool(self.observability.get('log_prompt_meta', False))
        self.prompt_preview_chars: int = int(self.observability.get('preview_chars', 0))
        self.audit_to_system_logs: bool = bool(self.observability.get('audit_to_system_logs', True))

        # åŠ è½½AIé…ç½®æ–‡ä»¶
        self.system_prompt = self._load_system_prompt()
        self.tools_definition = self._load_tools_definition()
        self.tool_param_schemas = {
            t.get('name'): t.get('parameters') for t in self.tools_definition.get('tools', [])
        }
        self.tool_return_schemas = {
            t.get('name'): t.get('returns') for t in self.tools_definition.get('tools', [])
        }
        
        # å¯¹è¯å†å²
        self.conversation_history = []
        
        # å·¥å…·æ˜ å°„è¡¨ï¼šAIå·¥å…·å -> MCPç«¯ç‚¹
        self.tool_mapping = {
            'get_kline_data': '/get_kline',
            'get_market_ticker': '/get_market_ticker', 
            'get_latest_price': '/get_latest_price',
            'get_account_balance': '/get_account_balance',
            'get_positions': '/get_positions',
            'calculate_risk_metrics': '/calculate_risk_metrics'
        }
        
        logger.info("AI Orchestrator initialized successfully")
        
        # å°è¯•åŠ è½½ JSON Schema æ ¡éªŒåº“
        try:
            from jsonschema import Draft7Validator  # noqa: F401
            self._jsonschema_available = True
        except Exception:
            self._jsonschema_available = False
            logger.warning("jsonschema not available; tool parameter validation will be basic only")
    
    def _load_system_prompt(self) -> str:
        """åŠ è½½AIç³»ç»Ÿæç¤ºè¯"""
        try:
            prompt_path = Path("config/AI_Trading_System_Prompt_V1.md")
            if prompt_path.exists():
                with open(prompt_path, 'r', encoding='utf-8') as f:
                    return f.read()
            else:
                logger.warning("System prompt file not found, using default")
                return "æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡åŒ–äº¤æ˜“åˆ†æå¸ˆã€‚"
        except Exception as e:
            logger.error(f"Error loading system prompt: {e}")
            return "æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡åŒ–äº¤æ˜“åˆ†æå¸ˆã€‚"
    
    def _load_tools_definition(self) -> Dict:
        """åŠ è½½å·¥å…·å®šä¹‰"""
        try:
            tools_path = Path("config/AI_Trading_System_Tools.json")
            if tools_path.exists():
                with open(tools_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                logger.warning("Tools definition file not found")
                return {"tools": []}
        except Exception as e:
            logger.error(f"Error loading tools definition: {e}")
            return {"tools": []}
    
    def _load_api_credentials(self):
        """åŠ è½½APIå‡­è¯"""
        import os
        from dotenv import load_dotenv
        
        load_dotenv()
        self.api_key = os.getenv("DASHSCOPE_API_KEY")
        self.mcp_api_key = os.getenv("MCP_API_KEY")
        
        if not self.api_key:
            raise ValueError("DASHSCOPE_API_KEY not found in environment variables")
        if not self.mcp_api_key:
            raise ValueError("MCP_API_KEY not found in environment variables")
    
    def execute_tool_call(self, tool_call: ToolCall) -> ToolResult:
        """
        æ‰§è¡ŒAIçš„å·¥å…·è°ƒç”¨è¯·æ±‚
        
        Args:
            tool_call: AIçš„å·¥å…·è°ƒç”¨è¯·æ±‚
            
        Returns:
            å·¥å…·è°ƒç”¨ç»“æœ
        """
        try:
            tool_name = tool_call.name
            
            # æ£€æŸ¥å·¥å…·æ˜¯å¦åœ¨æˆæƒåˆ—è¡¨ä¸­
            if tool_name not in self.tool_mapping:
                return ToolResult(
                    call_id=tool_call.call_id,
                    success=False,
                    error_message=f"æœªæˆæƒçš„å·¥å…·: {tool_name}"
                )
            
            # è·å–MCPç«¯ç‚¹
            mcp_endpoint = self.tool_mapping[tool_name]
            
            # æ„å»ºMCPè¯·æ±‚
            mcp_url = f"http://{self.mcp_host}:{self.mcp_port}{mcp_endpoint}"
            headers = {
                "Content-Type": "application/json",
                "X-API-Key": self.mcp_api_key
            }
            
            # è®°å½•å·¥å…·è°ƒç”¨
            logger.info(f"AIæ­£åœ¨è°ƒç”¨å·¥å…·: {tool_name} -> {mcp_endpoint}")
            logger.info(f"å·¥å…·å‚æ•°: {json.dumps(tool_call.parameters, ensure_ascii=False, indent=2)}")
            
            # å·¥å…·å…¥å‚ Schema æ ¡éªŒ
            try:
                self._validate_tool_parameters(tool_name, tool_call.parameters)
            except Exception as ve:
                logger.error(f"å·¥å…·å‚æ•°æ ¡éªŒå¤±è´¥: {ve}")
                return ToolResult(
                    call_id=tool_call.call_id,
                    success=False,
                    error_message=f"å‚æ•°ä¸ç¬¦åˆå·¥å…·å¥‘çº¦: {ve}",
                    name=tool_name,
                    parameters=tool_call.parameters
                )

            # æ ¹æ®å¥‘çº¦è½¬æ¢å‚æ•°åˆ° MCP ç«¯ç‚¹å®é™…éœ€è¦çš„æ ¼å¼
            outgoing_params: Dict[str, Any] = dict(tool_call.parameters or {})
            if tool_name == 'get_kline_data' and mcp_endpoint == '/get_kline':
                try:
                    timeframe = outgoing_params.get('timeframe')
                    limit = int(outgoing_params.get('limit', 100))
                    limit = max(1, min(limit, 300))
                    mapped_name = self._map_timeframe_to_authorized_filename(timeframe)
                    outgoing_params = {
                        'name': mapped_name,
                        'max_bars': limit
                    }
                except Exception as map_err:
                    return ToolResult(
                        call_id=tool_call.call_id,
                        success=False,
                        error_message=f"æ—¶é—´å‘¨æœŸæ˜ å°„å¤±è´¥: {map_err}",
                        name=tool_name,
                        parameters=tool_call.parameters
                    )

            # å‘èµ·è¯·æ±‚
            start_ms = time.perf_counter()
            # å‘é€è¯·æ±‚åˆ°MCPæœåŠ¡
            if mcp_endpoint in ['/get_kline']:
                # POSTè¯·æ±‚
                response = requests.post(
                    mcp_url,
                    headers=headers,
                    json=outgoing_params,
                    timeout=30
                )
            else:
                # GETè¯·æ±‚
                response = requests.get(
                    mcp_url,
                    headers=headers,
                    params=outgoing_params,
                    timeout=30
                )
            
            response.raise_for_status()
            result_data = response.json()

            # å·¥å…·è¿”å› Schema æ ¡éªŒ
            try:
                self._validate_tool_returns(tool_name, result_data)
            except Exception as ve:
                logger.error(f"å·¥å…·è¿”å›æ ¡éªŒå¤±è´¥: {ve}")
                return ToolResult(
                    call_id=tool_call.call_id,
                    success=False,
                    error_message=f"è¿”å›ä¸ç¬¦åˆå·¥å…·å¥‘çº¦: {ve}",
                    name=tool_name,
                    parameters=outgoing_params
                )
            
            # æˆåŠŸè¿”å›ç»“æœ
            logger.info(f"å·¥å…·è°ƒç”¨æˆåŠŸ: {tool_name}")
            latency_ms = (time.perf_counter() - start_ms) * 1000.0
            return ToolResult(
                call_id=tool_call.call_id,
                success=True,
                data=result_data,
                name=tool_name,
                parameters=outgoing_params,
                latency_ms=latency_ms,
                status_code=response.status_code
            )
            
        except requests.exceptions.RequestException as e:
            error_msg = f"MCPæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return ToolResult(
                call_id=tool_call.call_id,
                success=False,
                error_message=error_msg,
                name=tool_call.name,
                parameters=tool_call.parameters
            )
        except Exception as e:
            error_msg = f"å·¥å…·è°ƒç”¨å¼‚å¸¸: {str(e)}"
            logger.error(error_msg)
            return ToolResult(
                call_id=tool_call.call_id,
                success=False,
                error_message=error_msg,
                name=tool_call.name,
                parameters=tool_call.parameters
            )
    
    def send_ai_request(self, messages: List[Dict], tools: Optional[List[Dict]] = None) -> Dict:
        """
        å‘é€è¯·æ±‚ç»™AIæ¨¡å‹
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            
        Returns:
            AIæ¨¡å‹çš„å“åº”
        """
        try:
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "model": self.model,
                "messages": messages,
                "temperature": self.ai_config.get('temperature', 0.3),
                "max_tokens": self.ai_config.get('max_tokens', 4000)
            }
            
            # å¦‚æœæä¾›äº†å·¥å…·ï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­
            if tools:
                request_data["tools"] = tools
                request_data["tool_choice"] = "auto"
            
            # å‘é€è¯·æ±‚
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=request_data,
                timeout=self.ai_config.get('timeout', 60)
            )
            
            response.raise_for_status()
            return response.json()
            
        except Exception as e:
            logger.error(f"AIè¯·æ±‚å¤±è´¥: {e}")
            raise
    
    def analyze_market(self, analysis_request: str, context: Optional[Dict] = None) -> Dict:
        """
        æ‰§è¡Œå¸‚åœºåˆ†æè¯·æ±‚
        
        Args:
            analysis_request: åˆ†æè¯·æ±‚æè¿°
            context: å¯é€‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            åˆ†æç»“æœå’Œæ‰§è¡Œæ—¥å¿—
        """
        try:
            # åŠ è½½APIå‡­è¯
            self._load_api_credentials()
            
            # æ„å»ºç³»ç»Ÿæ¶ˆæ¯
            system_message = {
                "role": "system",
                "content": self.system_prompt
            }
            
            # æ„å»ºç”¨æˆ·è¯·æ±‚
            user_message = {
                "role": "user", 
                "content": f"åˆ†æè¯·æ±‚ï¼š{analysis_request}"
            }
            
            if context:
                user_message["content"] += f"\n\nä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{json.dumps(context, ensure_ascii=False, indent=2)}"
            
            # åˆå§‹åŒ–å¯¹è¯
            messages = [system_message, user_message]
            
            # è½¬æ¢å·¥å…·å®šä¹‰ä¸ºOpenAIæ ¼å¼
            openai_tools = self._convert_tools_to_openai_format()
            
            # æ‰§è¡Œå¤šè½®å¯¹è¯
            analysis_log: List[str] = []
            max_iterations = 10
            iteration = 0
            tool_calls_used = 0
            run_start_time = time.time()
            run_id = str(uuid.uuid4())
            token_usage = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
            tool_call_records: List[Dict[str, Any]] = []

            # è®°å½•æç¤ºè¯å…ƒä¿¡æ¯ï¼ˆè„±æ•ï¼‰
            try:
                if self.log_prompt_meta:
                    sp = self.system_prompt or ""
                    import hashlib
                    prompt_hash = hashlib.sha256(sp.encode('utf-8')).hexdigest()[:16]
                    preview = sp[: self.prompt_preview_chars] if self.prompt_preview_chars > 0 else ""
                    analysis_log.append(
                        f"Prompt meta: len={len(sp)}, sha256[0:16]={prompt_hash}, preview={preview!r}"
                    )
            except Exception:
                pass
            
            while iteration < max_iterations:
                iteration += 1
                analysis_log.append(f"--- ç¬¬{iteration}è½®å¯¹è¯ ---")
                if (time.time() - run_start_time) > self.analysis_timeout_seconds:
                    analysis_log.append("â±ï¸ è¾¾åˆ°åˆ†ææ€»æ—¶é•¿é™åˆ¶ï¼Œæå‰ç»“æŸ")
                    break
                
                # å‘é€è¯·æ±‚ç»™AI
                ai_response = self.send_ai_request(messages, openai_tools)

                # ç´¯è®¡ token ç”¨é‡ï¼ˆå¦‚å¯ç”¨ï¼‰
                try:
                    usage = ai_response.get('usage') or {}
                    token_usage['prompt_tokens'] += int(usage.get('prompt_tokens', 0))
                    token_usage['completion_tokens'] += int(usage.get('completion_tokens', 0))
                    token_usage['total_tokens'] += int(usage.get('total_tokens', usage.get('prompt_tokens', 0) + usage.get('completion_tokens', 0)))
                except Exception:
                    pass
                
                # è§£æAIå“åº”
                message = ai_response['choices'][0]['message']
                messages.append(message)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                tool_calls = message.get('tool_calls', [])
                
                if not tool_calls:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œåˆ†æå®Œæˆ
                    analysis_log.append("âœ… AIåˆ†æå®Œæˆï¼Œæ²¡æœ‰æ›´å¤šå·¥å…·è°ƒç”¨")
                    break
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_results = []
                for tool_call in tool_calls:
                    if tool_calls_used >= self.max_tool_calls:
                        analysis_log.append("ğŸ§® å·²è¾¾åˆ°max_tool_callsé™åˆ¶ï¼Œåœæ­¢æ‰§è¡Œæ›´å¤šå·¥å…·è°ƒç”¨")
                        break
                    function_call = tool_call['function']
                    
                    # åˆ›å»ºå·¥å…·è°ƒç”¨å¯¹è±¡
                    call_request = ToolCall(
                        name=function_call['name'],
                        parameters=json.loads(function_call['arguments']),
                        call_id=tool_call['id']
                    )
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    result = self.execute_tool_call(call_request)
                    tool_results.append(result)
                    tool_calls_used += 1
                    tool_call_records.append({
                        "name": result.name or call_request.name,
                        "parameters": result.parameters or call_request.parameters,
                        "success": result.success,
                        "latency_ms": result.latency_ms,
                        "status_code": result.status_code,
                        "call_id": result.call_id
                    })
                    
                    # è®°å½•åˆ°åˆ†ææ—¥å¿—
                    if result.success:
                        analysis_log.append(f"ğŸ”§ å·¥å…·è°ƒç”¨æˆåŠŸ: {call_request.name}")
                    else:
                        analysis_log.append(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {call_request.name} - {result.error_message}")
                
                # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                for tool_call, result in zip(tool_calls, tool_results):
                    tool_message = {
                        "role": "tool",
                        "tool_call_id": tool_call['id'],
                        "content": json.dumps(result.data if result.success else {"error": result.error_message}, ensure_ascii=False)
                    }
                    messages.append(tool_message)
            
            # è¿”å›æœ€ç»ˆç»“æœ
            final_text = messages[-1]['content'] if messages[-1]['role'] == 'assistant' else "åˆ†ææœªå®Œæˆ"
            structured_output = self._structure_final_analysis(final_text, tool_call_records)
            
            result_payload = {
                "success": True,
                "analysis": structured_output,
                "execution_log": analysis_log,
                "iterations": iteration,
                "tool_calls_used": tool_calls_used,
                "timestamp": datetime.utcnow().isoformat() + 'Z',
                "run_id": run_id,
                "token_usage": token_usage
            }

            # å†™å…¥ç³»ç»Ÿè¿è¡Œæ‘˜è¦
            if self.audit_to_system_logs:
                try:
                    # é™„åŠ  prompt å…ƒä¿¡æ¯åˆ°æ‘˜è¦
                    sp = self.system_prompt or ""
                    import hashlib
                    prompt_meta = {
                        "length": len(sp),
                        "sha256_16": hashlib.sha256(sp.encode('utf-8')).hexdigest()[:16]
                    }
                    if self.prompt_preview_chars > 0:
                        prompt_meta["preview"] = sp[: self.prompt_preview_chars]
                    result_payload["prompt_meta"] = prompt_meta
                    self._write_run_summary(run_id, result_payload)
                except Exception as werr:
                    logger.warning(f"å†™å…¥è¿è¡Œæ‘˜è¦å¤±è´¥: {werr}")

            return result_payload
            
        except Exception as e:
            logger.error(f"å¸‚åœºåˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis": None,
                "execution_log": [f"âŒ åˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}"],
                "timestamp": datetime.utcnow().isoformat() + 'Z'
            }
    
    def _convert_tools_to_openai_format(self) -> List[Dict]:
        """å°†å†…éƒ¨å·¥å…·å®šä¹‰è½¬æ¢ä¸ºOpenAI APIæ ¼å¼"""
        openai_tools = []
        
        for tool in self.tools_definition.get('tools', []):
            openai_tool = {
                "type": "function",
                "function": {
                    "name": tool['name'],
                    "description": tool['description'],
                    "parameters": tool['parameters']
                }
            }
            openai_tools.append(openai_tool)
        
        return openai_tools
    
    def _validate_tool_parameters(self, tool_name: str, params: Dict[str, Any]):
        """æ ¹æ® tools_definition å¯¹å·¥å…·å…¥å‚è¿›è¡Œæ ¡éªŒã€‚jsonschema å¯ç”¨åˆ™ä¸¥æ ¼æ ¡éªŒï¼Œå¦åˆ™åšåŸºæœ¬å¿…å¡«æ£€æŸ¥ã€‚"""
        schema = self.tool_param_schemas.get(tool_name)
        if not schema:
            return
        if self._jsonschema_available:
            try:
                from jsonschema import validate
                validate(instance=params or {}, schema=schema)
            except Exception as e:
                raise ValueError(str(e))
        else:
            required = (schema or {}).get('required', [])
            for key in required:
                if key not in (params or {}):
                    raise ValueError(f"ç¼ºå°‘å¿…å¡«å‚æ•°: {key}")
    
    def _validate_tool_returns(self, tool_name: str, result: Any):
        """æ ¹æ® tools_definition å¯¹å·¥å…·è¿”å›è¿›è¡Œæ ¡éªŒã€‚"""
        schema = self.tool_return_schemas.get(tool_name)
        if not schema:
            return
        if self._jsonschema_available:
            try:
                from jsonschema import validate
                validate(instance=result, schema=schema)
            except Exception as e:
                raise ValueError(str(e))
        else:
            # åŸºç¡€æ ¡éªŒï¼šå¦‚æœæ˜¯å¯¹è±¡å¹¶å£°æ˜äº†propertiesï¼Œåˆ™æ£€æŸ¥å…³é”®å­—æ®µå­˜åœ¨
            if isinstance(result, dict):
                properties = (schema or {}).get('properties', {})
                for key in properties.keys():
                    if key not in result:
                        # ä»…å¯¹å…³é”®è¾“å‡ºå­—æ®µåšåŸºæœ¬è¦æ±‚
                        if tool_name == 'get_kline_data' and key in ('data', 'metadata'):
                            raise ValueError(f"ç¼ºå°‘å…³é”®è¿”å›å­—æ®µ: {key}")
    
    def _map_timeframe_to_authorized_filename(self, timeframe: str) -> str:
        """æŠŠ timeframe æ˜ å°„åˆ° manifest.json ç™½åå•æ–‡ä»¶åã€‚ä¼˜å…ˆè¯»å– manifest æ ¡éªŒã€‚"""
        if not timeframe:
            raise ValueError("timeframe ä¸ºç©º")
        tf = str(timeframe).lower()
        storage_dir = self.config.get('storage', {}).get('base_directory', 'kline_data')
        manifest_path = Path(storage_dir) / 'manifest.json'
        candidate = f"{tf}/{tf}.csv"
        if manifest_path.exists():
            try:
                with open(manifest_path, 'r', encoding='utf-8') as f:
                    manifest = json.load(f)
                files = set(manifest.get('files', []))
                if candidate in files:
                    return candidate
                else:
                    raise ValueError(f"æ–‡ä»¶æœªæˆæƒ: {candidate}")
            except Exception as e:
                raise ValueError(f"è¯»å–manifestå¤±è´¥: {e}")
        return candidate
    
    def _structure_final_analysis(self, content: str, tool_call_records: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æŠŠæœ€ç»ˆå›ç­”æ•´ç†ä¸ºå›ºå®šç»“æ„ï¼Œä¾¿äºå‰ç«¯ä¸å®¡è®¡ä½¿ç”¨ã€‚"""
        def extract_section(text: str, marker: str) -> Optional[str]:
            if marker in text:
                start = text.find(marker)
                next_markers = [m for m in ["ğŸ“Š", "âš ï¸", "ğŸ’¡", "ğŸ”„", "ğŸ“‹"] if m != marker and m in text]
                ends = [text.find(m, start + 1) for m in next_markers]
                ends = [e for e in ends if e != -1]
                end = min(ends) if ends else len(text)
                return text[start:end].strip()
            return None

        analysis_plan = extract_section(content, "ğŸ“‹")
        analysis_report = extract_section(content, "ğŸ“Š")
        risk_assessment = extract_section(content, "âš ï¸")
        actionable_advice = extract_section(content, "ğŸ’¡")
        monitoring_notes = extract_section(content, "ğŸ”„")

        return {
            "analysis_plan": analysis_plan,
            "analysis_report": analysis_report,
            "risk_assessment": risk_assessment,
            "actionable_advice": actionable_advice,
            "monitoring_notes": monitoring_notes,
            "tool_calls": tool_call_records,
            "raw": content,
            "compliance_flags": {
                "has_analysis_plan": bool(analysis_plan),
                "has_analysis_report": bool(analysis_report),
                "has_risk_assessment": bool(risk_assessment),
                "has_actionable_advice": bool(actionable_advice)
            }
        }

    def _write_run_summary(self, run_id: str, payload: Dict[str, Any]):
        """æŠŠæœ¬æ¬¡åˆ†æè¿è¡Œæ‘˜è¦å†™å…¥ system_logsï¼Œå¹¶æ›´æ–° latest_run_summary.jsonã€‚"""
        system_logs_dir = Path('system_logs')
        system_logs_dir.mkdir(exist_ok=True)
        timestamp_str = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        out_file = system_logs_dir / f"analysis_summary_{timestamp_str}.json"
        with open(out_file, 'w', encoding='utf-8') as f:
            json.dump(payload, f, indent=2, ensure_ascii=False)
        latest_path = system_logs_dir / 'latest_run_summary.json'
        with open(latest_path, 'w', encoding='utf-8') as f:
            json.dump(payload, f, indent=2, ensure_ascii=False)
    
    def get_analysis_status(self) -> Dict:
        """è·å–åˆ†æç³»ç»ŸçŠ¶æ€"""
        return {
            "orchestrator_status": "active",
            "ai_model": self.model,
            "mcp_service": f"{self.mcp_host}:{self.mcp_port}",
            "available_tools": list(self.tool_mapping.keys()),
            "system_prompt_loaded": bool(self.system_prompt),
            "tools_definition_loaded": bool(self.tools_definition.get('tools')),
            "timestamp": datetime.utcnow().isoformat() + 'Z'
        }

# ä¾¿åˆ©å‡½æ•°ï¼šå¿«é€Ÿåˆ›å»ºåˆ†æå®ä¾‹
def create_orchestrator() -> AIOrchestrator:
    """åˆ›å»ºAIç¼–æ’å™¨å®ä¾‹"""
    return AIOrchestrator()

def quick_analysis(request: str, context: Optional[Dict] = None) -> Dict:
    """å¿«é€Ÿæ‰§è¡Œåˆ†æè¯·æ±‚"""
    orchestrator = create_orchestrator()
    return orchestrator.analyze_market(request, context)