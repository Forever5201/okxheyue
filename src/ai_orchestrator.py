"""
AIäº¤æ˜“ç³»ç»Ÿç¼–æ’å™¨ - é¡¹ç›®ç»ç†æ¨¡å¼
AI Trading System Orchestrator - Project Manager Pattern

å®ç°é€æ˜ã€å¯æ§çš„AIåˆ†æä»£ç†æ¶æ„ï¼š
- é¡¹ç›®ç»ç† (Pythonä»£ç ): ç®¡ç†æ•´ä¸ªæµç¨‹ï¼Œæ§åˆ¶èŠ‚å¥ï¼ŒéªŒè¯ç»“æœ
- AIåˆ†æå¸ˆ (AIæ¨¡å‹): åœ¨å®‰å…¨ç¯å¢ƒä¸­æ€è€ƒï¼Œå‘é¡¹ç›®ç»ç†è¯·æ±‚æ•°æ®å’Œå·¥å…·
"""

import json
import logging
import requests
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

from src.logger import setup_logger
from src.config_loader import ConfigLoader

logger = setup_logger()

@dataclass
class ToolCall:
    """å·¥å…·è°ƒç”¨è¯·æ±‚"""
    name: str
    parameters: Dict[str, Any]
    call_id: str = None

@dataclass  
class ToolResult:
    """å·¥å…·è°ƒç”¨ç»“æœ"""
    call_id: str
    success: bool
    data: Any = None
    error_message: str = None

class AIOrchestrator:
    """
    AIç³»ç»Ÿç¼–æ’å™¨ - é¡¹ç›®ç»ç†æ¨¡å¼
    
    èŒè´£ï¼š
    1. åŠ è½½AIè¡Œä¸ºå‡†åˆ™å’Œå·¥å…·å®šä¹‰
    2. ç®¡ç†ä¸AIæ¨¡å‹çš„å¯¹è¯å¾ªç¯
    3. ç¿»è¯‘AIå·¥å…·è¯·æ±‚åˆ°æœ¬åœ°MCPæœåŠ¡è°ƒç”¨
    4. éªŒè¯å’Œå®¡æ ¸AIçš„åˆ†æç»“æœ
    """
    
    def __init__(self, config_path="config/enhanced_config.yaml"):
        """
        åˆå§‹åŒ–AIç¼–æ’å™¨
        
        Args:
            config_path: ä¸»é…ç½®æ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½ç³»ç»Ÿé…ç½®
        self.config_loader = ConfigLoader(config_path)
        self.config = self.config_loader.load_config()
        
        # AIé…ç½®
        self.ai_config = self.config.get('ai_analysis', {}).get('qwen', {})
        self.api_key = None  # å°†ä»ç¯å¢ƒå˜é‡åŠ è½½
        self.base_url = self.ai_config.get('base_url', 'https://dashscope.aliyuncs.com/compatible-mode/v1')
        self.model = self.ai_config.get('model', 'qwen-plus')
        
        # MCPæœåŠ¡é…ç½®
        self.mcp_config = self.config.get('mcp_service', {})
        self.mcp_host = self.mcp_config.get('host', 'localhost')
        self.mcp_port = self.mcp_config.get('port', 5000)
        self.mcp_api_key = None  # å°†ä»ç¯å¢ƒå˜é‡åŠ è½½
        
        # åŠ è½½AIé…ç½®æ–‡ä»¶
        self.system_prompt = self._load_system_prompt()
        self.tools_definition = self._load_tools_definition()
        
        # å¯¹è¯å†å²
        self.conversation_history = []
        
        # å·¥å…·æ˜ å°„è¡¨ï¼šAIå·¥å…·å -> MCPç«¯ç‚¹
        self.tool_mapping = {
            'get_kline_data': '/get_kline',
            'get_market_ticker': '/get_market_ticker', 
            'get_latest_price': '/get_latest_price',
            'get_account_balance': '/get_account_balance',
            'get_positions': '/get_positions',
            'calculate_risk_metrics': '/calculate_risk_metrics'
        }
        
        logger.info("AI Orchestrator initialized successfully")
    
    def _load_system_prompt(self) -> str:
        """åŠ è½½AIç³»ç»Ÿæç¤ºè¯"""
        try:
            prompt_path = Path("config/ai_trading_system_prompt.md")
            if prompt_path.exists():
                with open(prompt_path, 'r', encoding='utf-8') as f:
                    return f.read()
            else:
                logger.warning("System prompt file not found, using default")
                return "æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡åŒ–äº¤æ˜“åˆ†æå¸ˆã€‚"
        except Exception as e:
            logger.error(f"Error loading system prompt: {e}")
            return "æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡åŒ–äº¤æ˜“åˆ†æå¸ˆã€‚"
    
    def _load_tools_definition(self) -> Dict:
        """åŠ è½½å·¥å…·å®šä¹‰"""
        try:
            tools_path = Path("config/ai_trading_system_tools.json")
            if tools_path.exists():
                with open(tools_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                logger.warning("Tools definition file not found")
                return {"tools": []}
        except Exception as e:
            logger.error(f"Error loading tools definition: {e}")
            return {"tools": []}
    
    def _load_api_credentials(self):
        """åŠ è½½APIå‡­è¯"""
        import os
        from dotenv import load_dotenv
        
        load_dotenv()
        self.api_key = os.getenv("DASHSCOPE_API_KEY")
        self.mcp_api_key = os.getenv("MCP_API_KEY")
        
        if not self.api_key:
            raise ValueError("DASHSCOPE_API_KEY not found in environment variables")
        if not self.mcp_api_key:
            raise ValueError("MCP_API_KEY not found in environment variables")
    
    def execute_tool_call(self, tool_call: ToolCall) -> ToolResult:
        """
        æ‰§è¡ŒAIçš„å·¥å…·è°ƒç”¨è¯·æ±‚
        
        Args:
            tool_call: AIçš„å·¥å…·è°ƒç”¨è¯·æ±‚
            
        Returns:
            å·¥å…·è°ƒç”¨ç»“æœ
        """
        try:
            tool_name = tool_call.name
            
            # æ£€æŸ¥å·¥å…·æ˜¯å¦åœ¨æˆæƒåˆ—è¡¨ä¸­
            if tool_name not in self.tool_mapping:
                return ToolResult(
                    call_id=tool_call.call_id,
                    success=False,
                    error_message=f"æœªæˆæƒçš„å·¥å…·: {tool_name}"
                )
            
            # è·å–MCPç«¯ç‚¹
            mcp_endpoint = self.tool_mapping[tool_name]
            
            # æ„å»ºMCPè¯·æ±‚
            mcp_url = f"http://{self.mcp_host}:{self.mcp_port}{mcp_endpoint}"
            headers = {
                "Content-Type": "application/json",
                "X-API-Key": self.mcp_api_key
            }
            
            # è®°å½•å·¥å…·è°ƒç”¨
            logger.info(f"AIæ­£åœ¨è°ƒç”¨å·¥å…·: {tool_name} -> {mcp_endpoint}")
            logger.info(f"å·¥å…·å‚æ•°: {json.dumps(tool_call.parameters, ensure_ascii=False, indent=2)}")
            
            # å‘é€è¯·æ±‚åˆ°MCPæœåŠ¡
            if mcp_endpoint in ['/get_kline']:
                # POSTè¯·æ±‚
                response = requests.post(mcp_url, 
                                       headers=headers,
                                       json=tool_call.parameters,
                                       timeout=30)
            else:
                # GETè¯·æ±‚
                response = requests.get(mcp_url,
                                      headers=headers,
                                      params=tool_call.parameters,
                                      timeout=30)
            
            response.raise_for_status()
            result_data = response.json()
            
            # æˆåŠŸè¿”å›ç»“æœ
            logger.info(f"å·¥å…·è°ƒç”¨æˆåŠŸ: {tool_name}")
            return ToolResult(
                call_id=tool_call.call_id,
                success=True,
                data=result_data
            )
            
        except requests.exceptions.RequestException as e:
            error_msg = f"MCPæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return ToolResult(
                call_id=tool_call.call_id,
                success=False,
                error_message=error_msg
            )
        except Exception as e:
            error_msg = f"å·¥å…·è°ƒç”¨å¼‚å¸¸: {str(e)}"
            logger.error(error_msg)
            return ToolResult(
                call_id=tool_call.call_id,
                success=False,
                error_message=error_msg
            )
    
    def send_ai_request(self, messages: List[Dict], tools: List[Dict] = None) -> Dict:
        """
        å‘é€è¯·æ±‚ç»™AIæ¨¡å‹
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            
        Returns:
            AIæ¨¡å‹çš„å“åº”
        """
        try:
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "model": self.model,
                "messages": messages,
                "temperature": self.ai_config.get('temperature', 0.3),
                "max_tokens": self.ai_config.get('max_tokens', 4000)
            }
            
            # å¦‚æœæä¾›äº†å·¥å…·ï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­
            if tools:
                request_data["tools"] = tools
                request_data["tool_choice"] = "auto"
            
            # å‘é€è¯·æ±‚
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=request_data,
                timeout=self.ai_config.get('timeout', 60)
            )
            
            response.raise_for_status()
            return response.json()
            
        except Exception as e:
            logger.error(f"AIè¯·æ±‚å¤±è´¥: {e}")
            raise
    
    def analyze_market(self, analysis_request: str, context: Dict = None) -> Dict:
        """
        æ‰§è¡Œå¸‚åœºåˆ†æè¯·æ±‚
        
        Args:
            analysis_request: åˆ†æè¯·æ±‚æè¿°
            context: å¯é€‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            åˆ†æç»“æœå’Œæ‰§è¡Œæ—¥å¿—
        """
        try:
            # åŠ è½½APIå‡­è¯
            self._load_api_credentials()
            
            # æ„å»ºç³»ç»Ÿæ¶ˆæ¯
            system_message = {
                "role": "system",
                "content": self.system_prompt
            }
            
            # æ„å»ºç”¨æˆ·è¯·æ±‚
            user_message = {
                "role": "user", 
                "content": f"åˆ†æè¯·æ±‚ï¼š{analysis_request}"
            }
            
            if context:
                user_message["content"] += f"\n\nä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{json.dumps(context, ensure_ascii=False, indent=2)}"
            
            # åˆå§‹åŒ–å¯¹è¯
            messages = [system_message, user_message]
            
            # è½¬æ¢å·¥å…·å®šä¹‰ä¸ºOpenAIæ ¼å¼
            openai_tools = self._convert_tools_to_openai_format()
            
            # æ‰§è¡Œå¤šè½®å¯¹è¯
            analysis_log = []
            max_iterations = 10  # é˜²æ­¢æ— é™å¾ªç¯
            iteration = 0
            
            while iteration < max_iterations:
                iteration += 1
                analysis_log.append(f"--- ç¬¬{iteration}è½®å¯¹è¯ ---")
                
                # å‘é€è¯·æ±‚ç»™AI
                ai_response = self.send_ai_request(messages, openai_tools)
                
                # è§£æAIå“åº”
                message = ai_response['choices'][0]['message']
                messages.append(message)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                tool_calls = message.get('tool_calls', [])
                
                if not tool_calls:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œåˆ†æå®Œæˆ
                    analysis_log.append("âœ… AIåˆ†æå®Œæˆï¼Œæ²¡æœ‰æ›´å¤šå·¥å…·è°ƒç”¨")
                    break
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_results = []
                for tool_call in tool_calls:
                    function_call = tool_call['function']
                    
                    # åˆ›å»ºå·¥å…·è°ƒç”¨å¯¹è±¡
                    call_request = ToolCall(
                        name=function_call['name'],
                        parameters=json.loads(function_call['arguments']),
                        call_id=tool_call['id']
                    )
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    result = self.execute_tool_call(call_request)
                    tool_results.append(result)
                    
                    # è®°å½•åˆ°åˆ†ææ—¥å¿—
                    if result.success:
                        analysis_log.append(f"ğŸ”§ å·¥å…·è°ƒç”¨æˆåŠŸ: {call_request.name}")
                    else:
                        analysis_log.append(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {call_request.name} - {result.error_message}")
                
                # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                for tool_call, result in zip(tool_calls, tool_results):
                    tool_message = {
                        "role": "tool",
                        "tool_call_id": tool_call['id'],
                        "content": json.dumps(result.data if result.success else {"error": result.error_message}, ensure_ascii=False)
                    }
                    messages.append(tool_message)
            
            # è¿”å›æœ€ç»ˆç»“æœ
            final_response = messages[-1]['content'] if messages[-1]['role'] == 'assistant' else "åˆ†ææœªå®Œæˆ"
            
            return {
                "success": True,
                "analysis": final_response,
                "execution_log": analysis_log,
                "iterations": iteration,
                "timestamp": datetime.utcnow().isoformat() + 'Z'
            }
            
        except Exception as e:
            logger.error(f"å¸‚åœºåˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis": None,
                "execution_log": [f"âŒ åˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}"],
                "timestamp": datetime.utcnow().isoformat() + 'Z'
            }
    
    def _convert_tools_to_openai_format(self) -> List[Dict]:
        """å°†å†…éƒ¨å·¥å…·å®šä¹‰è½¬æ¢ä¸ºOpenAI APIæ ¼å¼"""
        openai_tools = []
        
        for tool in self.tools_definition.get('tools', []):
            openai_tool = {
                "type": "function",
                "function": {
                    "name": tool['name'],
                    "description": tool['description'],
                    "parameters": tool['parameters']
                }
            }
            openai_tools.append(openai_tool)
        
        return openai_tools
    
    def get_analysis_status(self) -> Dict:
        """è·å–åˆ†æç³»ç»ŸçŠ¶æ€"""
        return {
            "orchestrator_status": "active",
            "ai_model": self.model,
            "mcp_service": f"{self.mcp_host}:{self.mcp_port}",
            "available_tools": list(self.tool_mapping.keys()),
            "system_prompt_loaded": bool(self.system_prompt),
            "tools_definition_loaded": bool(self.tools_definition.get('tools')),
            "timestamp": datetime.utcnow().isoformat() + 'Z'
        }

# ä¾¿åˆ©å‡½æ•°ï¼šå¿«é€Ÿåˆ›å»ºåˆ†æå®ä¾‹
def create_orchestrator() -> AIOrchestrator:
    """åˆ›å»ºAIç¼–æ’å™¨å®ä¾‹"""
    return AIOrchestrator()

def quick_analysis(request: str, context: Dict = None) -> Dict:
    """å¿«é€Ÿæ‰§è¡Œåˆ†æè¯·æ±‚"""
    orchestrator = create_orchestrator()
    return orchestrator.analyze_market(request, context)