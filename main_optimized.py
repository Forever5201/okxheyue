"""
AIäº¤æ˜“ç³»ç»Ÿä¸»å…¥å£ - ä¼˜åŒ–ç‰ˆæœ¬
Optimized Main Entry Point for AI Trading System

è§£å†³æ•°æ®è·å–é˜»å¡é—®é¢˜ï¼Œæä¾›å®æ—¶è¿›åº¦åé¦ˆ
"""

import os
import json
import time
import asyncio
import concurrent.futures
from datetime import datetime, timezone
from pathlib import Path
from dotenv import load_dotenv

from typing import Dict, Any
from src.logger import setup_logger
from src.enhanced_data_manager import EnhancedDataManager
from src.mcp_service import app as mcp_app
from src.ai_orchestrator import AIOrchestrator

logger = setup_logger()

class OptimizedAITradingSystem:
    def __init__(self):
        """åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆAIäº¤æ˜“ç³»ç»Ÿ"""
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
        required_vars = ['OKX_API_KEY', 'OKX_API_SECRET', 'OKX_API_PASSPHRASE', 'MCP_API_KEY', 'DASHSCOPE_API_KEY']
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            error_msg = f"Missing required environment variables: {', '.join(missing_vars)}"
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        try:
            self.data_manager = EnhancedDataManager()
            logger.info("âœ… Optimized AI Trading System initialized successfully")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize data manager: {e}")
            raise
        
        # åˆå§‹åŒ–AIç³»ç»Ÿ
        self._init_ai_system()
        
        # ç³»ç»ŸçŠ¶æ€
        self.is_running = False
        self.last_update = None
    
    def _init_ai_system(self):
        """åˆå§‹åŒ–AIåˆ†æç³»ç»Ÿ"""
        try:
            config = self.data_manager.config
            ai_analysis_config = config.get('ai_analysis', {})
            
            if not ai_analysis_config.get('enabled', True):
                logger.info("AI analysis system is disabled in configuration")
                self.ai_orchestrator = None
                return
            
            self.ai_orchestrator = AIOrchestrator()
            logger.info("âœ… AI Orchestrator initialized successfully")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize AI Orchestrator: {e}")
            self.ai_orchestrator = None
    
    def run_optimized_data_fetch(self):
        """è¿è¡Œä¼˜åŒ–çš„æ•°æ®è·å–æµç¨‹"""
        logger.info("ğŸš€ å¯åŠ¨ä¼˜åŒ–æ•°æ®è·å–æµç¨‹...")
        
        try:
            # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
            timeframes_config = self.data_manager.config.get('timeframes', {})
            total_timeframes = sum(len(tfs) for tfs in timeframes_config.values())
            
            print(f"ğŸ“Š ç³»ç»Ÿé…ç½®:")
            print(f"   - æ€»æ—¶é—´å‘¨æœŸ: {total_timeframes}")
            for category, tfs in timeframes_config.items():
                print(f"   - {category}: {', '.join(tfs)}")
            print()
            
            # å¹¶å‘è·å–æ•°æ®
            logger.info("ğŸ”„ å¼€å§‹å¹¶å‘æ•°æ®è·å–...")
            start_time = time.time()
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                # æäº¤ä»»åŠ¡
                account_future = executor.submit(self._safe_get_account_summary)
                market_future = executor.submit(self._safe_get_market_summary)
                kline_future = executor.submit(self.data_manager.fetch_and_process_kline_data)
                
                # ç­‰å¾…Kçº¿æ•°æ®ï¼ˆä¸»è¦ä»»åŠ¡ï¼‰
                print("â³ æ­£åœ¨è·å–Kçº¿æ•°æ®...")
                try:
                    results = kline_future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                    elapsed = time.time() - start_time
                    
                    success_count = len(results.get('success', []))
                    failed_count = len(results.get('failed', []))
                    
                    print(f"âœ… Kçº¿æ•°æ®è·å–å®Œæˆ! ({elapsed:.1f}ç§’)")
                    print(f"   - æˆåŠŸ: {success_count} ä¸ªæ—¶é—´å‘¨æœŸ")
                    if failed_count > 0:
                        print(f"   - å¤±è´¥: {failed_count} ä¸ªæ—¶é—´å‘¨æœŸ")
                        for failed in results.get('failed', []):
                            print(f"     â€¢ {failed.get('timeframe')}: {failed.get('reason')}")
                    
                except concurrent.futures.TimeoutError:
                    logger.error("â° Kçº¿æ•°æ®è·å–è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰")
                    return {'success': [], 'failed': [], 'error': 'K-line data fetch timeout'}
                
                # è·å–å…¶ä»–ä¿¡æ¯ï¼ˆéé˜»å¡ï¼‰
                try:
                    account_summary = account_future.result(timeout=30)
                    print("âœ… è´¦æˆ·ä¿¡æ¯è·å–å®Œæˆ")
                except:
                    logger.warning("âš ï¸ è´¦æˆ·ä¿¡æ¯è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                    account_summary = {'error': 'Failed to fetch account info'}
                
                try:
                    market_summary = market_future.result(timeout=30)
                    print("âœ… å¸‚åœºä¿¡æ¯è·å–å®Œæˆ")
                except:
                    logger.warning("âš ï¸ å¸‚åœºä¿¡æ¯è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                    market_summary = {'error': 'Failed to fetch market info'}
            
            # ä¿å­˜è¿è¡Œæ‘˜è¦
            self._save_run_summary(results, account_summary, market_summary)
            
            # è§¦å‘AIåˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.ai_orchestrator and success_count > 0:
                logger.info("ğŸ¤– è§¦å‘AIåˆ†æ...")
                self._trigger_analysis_if_enabled(results)
            
            self.last_update = datetime.now(timezone.utc)
            total_elapsed = time.time() - start_time
            
            print(f"\nğŸ‰ æ•°æ®è·å–æµç¨‹å®Œæˆ!")
            print(f"   - æ€»è€—æ—¶: {total_elapsed:.1f}ç§’")
            print(f"   - æˆåŠŸç‡: {success_count}/{total_timeframes} ({success_count/total_timeframes*100:.1f}%)")
            
            return results
            
        except Exception as e:
            logger.error(f"ğŸ’¥ æ•°æ®è·å–æµç¨‹å¼‚å¸¸: {e}")
            return {'success': [], 'failed': [], 'error': str(e)}
    
    def _safe_get_account_summary(self):
        """å®‰å…¨è·å–è´¦æˆ·æ‘˜è¦"""
        try:
            return self.data_manager.get_account_summary()
        except Exception as e:
            logger.warning(f"è´¦æˆ·ä¿¡æ¯è·å–å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _safe_get_market_summary(self):
        """å®‰å…¨è·å–å¸‚åœºæ‘˜è¦"""
        try:
            return self.data_manager.get_market_summary()
        except Exception as e:
            logger.warning(f"å¸‚åœºä¿¡æ¯è·å–å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _save_run_summary(self, fetch_results, account_summary, market_summary):
        """ä¿å­˜è¿è¡Œæ‘˜è¦"""
        try:
            summary = {
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'fetch_results': fetch_results,
                'account_summary': account_summary,
                'market_summary': market_summary,
                'system_status': {
                    'is_running': self.is_running,
                    'last_update': self.last_update.isoformat() if self.last_update else None
                }
            }
            
            summary_dir = Path('system_logs')
            summary_dir.mkdir(exist_ok=True)
            
            timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
            summary_file = summary_dir / f'run_summary_{timestamp_str}.json'
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“ è¿è¡Œæ‘˜è¦å·²ä¿å­˜: {summary_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜è¿è¡Œæ‘˜è¦å¤±è´¥: {e}")
    
    def _trigger_analysis_if_enabled(self, data_results: Dict[str, Any]):
        """è§¦å‘AIåˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
        if not self.ai_orchestrator:
            logger.debug("AI Orchestrator not available, skipping analysis")
            return
        
        try:
            successful_timeframes = len(data_results.get('success', []))
            failed_timeframes = len(data_results.get('failed', []))
            timeframes = [tf.get('timeframe') for tf in data_results.get('success', [])]
            
            analysis_request = f"""è¯·åˆ†ææœ€æ–°çš„å¸‚åœºæ•°æ®ã€‚
            
æ•°æ®æ›´æ–°æ‘˜è¦ï¼š
- æˆåŠŸè·å– {successful_timeframes} ä¸ªæ—¶é—´å‘¨æœŸæ•°æ®
- å¤±è´¥ {failed_timeframes} ä¸ªæ—¶é—´å‘¨æœŸ
- å¯ç”¨æ—¶é—´å‘¨æœŸï¼š{', '.join(timeframes)}
- æ›´æ–°æ—¶é—´ï¼š{datetime.now(timezone.utc).isoformat()}

è¯·åŸºäºæœ€æ–°æ•°æ®è¿›è¡Œå¸‚åœºåˆ†æï¼Œå¹¶æä¾›äº¤æ˜“å»ºè®®ã€‚"""

            logger.info("ğŸ§  å¼€å§‹AIå¸‚åœºåˆ†æ...")
            analysis_result = self.ai_orchestrator.analyze_market(analysis_request)
            
            if analysis_result.get('success', False):
                logger.info("âœ… AIåˆ†æå®Œæˆ")
                print("ğŸ§  AIåˆ†æå·²å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° system_logs/")
            else:
                logger.error(f"âŒ AIåˆ†æå¤±è´¥: {analysis_result.get('error', 'Unknown error')}")
            
        except Exception as e:
            logger.error(f"AIåˆ†æè§¦å‘å¤±è´¥: {e}")
    
    def start_ai_analysis_system(self):
        """å¯åŠ¨AIåˆ†æç³»ç»Ÿ"""
        if not self.ai_orchestrator:
            logger.info("AI Orchestrator not initialized, skipping start")
            return
        
        try:
            status = self.ai_orchestrator.get_analysis_status()
            logger.info("ğŸ¤– AI Analysis System status verified")
            logger.info(f"Available tools: {status.get('available_tools', [])}")
            print("ğŸ¤– AIåˆ†æç³»ç»Ÿå·²å°±ç»ª")
            
        except Exception as e:
            logger.error(f"Failed to start AI analysis system: {e}")

def run_mcp_service():
    """è¿è¡ŒMCPæœåŠ¡"""
    import uvicorn
    logger.info("ğŸš€ Starting MCP service on port 5000...")
    
    if not os.getenv('MCP_API_KEY'):
        logger.error("âŒ MCP_API_KEY not set!")
        return
    
    try:
        uvicorn.run(
            "main_optimized:mcp_app", 
            host="0.0.0.0", 
            port=5000, 
            log_level="info",
            reload=False
        )
    except Exception as e:
        logger.error(f"MCP service error: {e}")

def main():
    """ä¸»å‡½æ•° - ä¼˜åŒ–ç‰ˆæœ¬"""
    print("=" * 60)
    print("ğŸš€ AI Trading System Starting (Optimized Version)")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        trading_system = OptimizedAITradingSystem()
        
        # å¯åŠ¨AIåˆ†æç³»ç»Ÿ
        print("\nğŸ¤– å¯åŠ¨AIåˆ†æç³»ç»Ÿ...")
        trading_system.start_ai_analysis_system()
        
        # æ‰§è¡Œä¼˜åŒ–çš„æ•°æ®è·å–
        print("\nğŸ“Š æ‰§è¡Œä¼˜åŒ–æ•°æ®è·å–...")
        initial_results = trading_system.run_optimized_data_fetch()
        
        # å¯åŠ¨MCPæœåŠ¡
        print(f"\nğŸš€ å¯åŠ¨MCPæœåŠ¡ (ç«¯å£ 5000)...")
        print("ğŸ“Š ç³»ç»Ÿå·²å°±ç»ª - AIç°åœ¨å¯ä»¥é€šè¿‡MCPè®¿é—®æ•°æ®")
        print("\n" + "=" * 60)
        print("âœ… ç³»ç»Ÿå¯åŠ¨å®Œæˆ!")
        print("ğŸŒ MCPæœåŠ¡è¿è¡Œä¸­... æŒ‰ Ctrl+C åœæ­¢")
        print("=" * 60)
        
        # è¿è¡ŒMCPæœåŠ¡ï¼ˆä¸»çº¿ç¨‹ï¼‰
        run_mcp_service()
        
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ç”¨æˆ·ç»ˆæ­¢ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
        logger.error(f"System error: {e}")
    finally:
        print("\nğŸ‘‹ AIäº¤æ˜“ç³»ç»Ÿå·²åœæ­¢")

if __name__ == "__main__":
    main()